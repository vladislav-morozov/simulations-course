---
title: "Evaluating Confidence Intervals"
subtitle: "Understanding Actual Coverage and Length Properties"
author: Vladislav Morozov  
format:
  revealjs:
    include-in-header: 
      text: |
        <meta name="description" content="Learn (lecture note slides)"/> 
    width: 1150
    slide-number: true
    sc-sb-title: true
    incremental: true   
    logo: ../../themes/favicon.ico
    footer: "Evaluating Confidence Intervals"
    footer-logo-link: "https://vladislav-morozov.github.io/simulations-course/"
    theme: ../../themes/slides_theme.scss
    toc: TRUE
    toc-depth: 2
    toc-title: Contents
    transition: convex
    transition-speed: fast
slide-level: 4
title-slide-attributes:
    data-background-color: "#3c165cff"
    data-footer: " "
filters:
  - reveal-header 
embed-resources: true
include-in-header: ../../themes/mathjax.html 
highlight-style: tango
open-graph:
    description: "Learn  (lecture note slides)" 
---






## Introduction {background="#00100F"}
 
  
```{python}
import matplotlib.pyplot as plt
import numpy as np

from scipy.stats import chi2
BG_COLOR = "whitesmoke"
THEME_COLOR = "#3c165c"
```

### Lecture Info {background="#43464B"}

#### Learning Outcomes

This lecture is about evaluating confidence intervals

<br>

By the end, you should be able to

 
- Describe  
 
 


#### References 
 
<br>

::: {.nonincremental}

 
- - [My slides from undergraduate econometrics](https://vladislav-morozov.github.io/econometrics-2/slides/vector/ols-inference.html) for some basic theory on univariate confidence intervals

:::

 
  


### Motivating Example {background="#43464B"}

#### Setting and Estimators

Suppose that observe an IID sample $X_1, \dots, X_N$ where
$$
X_i \sim N(\mu, \sigma^2)
$$
We estimate $\mu$ and $\sigma^2$ with their maximum likelihood estimators

$$
\hat{\mu} = \dfrac{1}{N}\sum_{i=1}^N X_i, \quad \hat{\sigma}^2 = \dfrac{1}{N}\sum_{i=1}^{N}(X_i -\bar{X})^2
$$

#### Towards Confidence Intervals

::: {.left-color}

In practice usually want to quantify uncertainty using confidence intervals

:::

- Can construct based on exact sampling distribution of $\hat{\mu}$ and $\hat{\sigma}^2$
- More often and generally, use asymptotic normality approximations, e.g. that if $\mu=0$, then under any distribution of data

$$
\sqrt{N}(\hat{\sigma}^2 - \sigma^2) \xrightarrow{d} N(0, \E[X_i^4]-\sigma^4)
$$

::: {.footer}

Can prove the above asymptotic result using the [delta method](https://vladislav-morozov.github.io/econometrics-2/slides/vector/ols-delta-method.html)

:::

#### Motivating Issue: Errors in Mean vs. in Variance

- Suppose that true values are $\mu=0$ and $\sigma^2 = 0.1$
- For the mean: you can make the same mistake in both directions: e.g. you can underestimate or overestimate the mean by $0.5$
- You can also overestimate $\sigma^2$ by 0.5
 
::: {.left-color}

But you cannot underestimate $\sigma^2$ by $0.5$ (which would mean an estimate of $-0.4$)

$\Rightarrow$ Distribution of estimation errors $(\sigma^2-\sigma^2)$ cannot be symmetric
:::

#### Simulation Question of Today

- Asymmetry of error distribution $\Rightarrow$ maybe asymptotic normal (symmetric) approximation is not good?
- This effect may be more pronounced when $\sigma$ is small (less space for underestimation)
- Does it affect he "quality" of asymptotic confidence intervals for $\sigma^2$?


. . . 

::: {.left-color}

Today: check numerically whether confidence intervals properties change as $\sigma^2\to 0$

:::

::: {.footer}

There is a lot of theory work about things going wrong when parameters may be on the boundary. See [@Andrews1999EstimationWhenParameter; @Andrews2000InconsistencyBootstrapWhen; @Andrews2001TestingWhenParameter]

:::

## Theory Essentials for Confidence Intervals {background="#00100F"}

### Definitions and Examples {background="#43464B"}


#### Confidence Sets: Definition


<div class="rounded-box">

::: {#def-vector-inference-conf-set}

1. A <span class="highlight"> $(1-\alpha)\times 100\%$ confidence set for $\theta$ </span> ($\theta\in\R^p$) is a random set $S(X_1, \dots, X_N)\subseteq \R^p$  
$$ \scriptsize
P(\theta \in S(X_1, \dots, X_N)) = 1-\alpha
$$

1. $S(\cdot, \cdots)$ is an <span class="highlight">asymptotic $(1-\alpha)\times 100\%$ confidence set for $\theta$ </span>  if $\lim_{N\to\infty} P(\theta \in S(X_1, \dots, X_N)) = 1-\alpha$

2. $P(\theta \in S(X_1, \dots, X_N))$ is the <span class="highlight">coverage</span> of $S$

:::


</div>


::: footer

:::

#### Confidence Sets as Set Estimators

Suppose that we are interested in some $\btheta\in \R^p$

::: {.left-color}

Confidence sets can be viewed as <span class="highlight">set estimators</span> —  return a whole set of values in $\R^p$ as a collection of guesses for $\btheta$


:::
  
<br>

- Confidence sets — intervals estimators with coverage guarantees
- Should contrast with <span class="highlight">point estimators</span> (e.g. OLS, IV, etc.) — give only one point

#### Familiar Example: CI Based on Asymptotic Normality
  
<div class="rounded-box">

::: {#prp-vector-inference-ci}

Suppose that $\sqrt{N}(\hat{\theta} - \theta) \xrightarrow{d} N(0, \avar(\hat{\theta}))$. Let $\widehat{\avar}(\hat{\theta})\xrightarrow{p} \avar(\hat{\theta})$.


The confidence interval
$$ \small \hspace{-1.6cm}
S = \left[  \hat{\theta} -  z_{1-\alpha/2} \sqrt{ \frac{\widehat{\avar}(\hat{\theta})}{N} }, \hat{\theta}+  z_{1-\alpha/2} \sqrt{ \frac{\widehat{\avar}(\hat{\theta})}{N} }  \right]
$$ {#eq-vector-inference-basic-ci}
has asymptotic coverage $(1-\alpha)\times 100\%$

:::

</div>


#### Connection to Tests: Test Inversion

There is an equivalent way to construct the confidence interval ([-@eq-vector-inference-basic-ci])

- Recall $t$-statistic for $H_0: \theta = c$
- $S$ is the set of all $c$ for which the $t$-test does not reject

. . . 

<br>

::: {.left-color}


An example of <span class="highlight">test inversion</span> and equivalence between testing and confidence intervals

:::

 

#### Interpetation of Confidence Interval

Recall interpretation of $95\%$ coverage:

::: {.left-color}

- Suppose we draw many samples of the same size 
- In ~95% of the samples the CI will fall "on top" of the true parameter value



:::

<br>

Notice: interpretation aligns with what we actually do in Monte Carlo
 
### Motivating Example {background="#43464B"}

#### Metrics for Evaluating Confidence Intervals

<br>

There are two key metrics for looking at confidence intervals in simulations

1. Coverage: what the actual coverage is 
2. (Average) length

::: {.left-color}

Generally prefer shorter intervals with coverage that is close to the nominal level

:::

#### Metric: Actual Coverage

How do you evaluate coverage? 

<br>

::: {.left-color}

Draw many datasets and in each sample $s$

- Compute CI = $[\hat{a}_s, \hat{b}_s]$
- Record $\text{Length}_s = \hat{b}_s - \hat{a}_s$

Report estimated average of $\text{Length}_s$ over $s$
:::


#### Metric: Average Length


Similar story for length:

::: {.left-color}

Draw many datasets and in each sample $s$

- Compute CI
- Check if CI include the true parameter and record inclusion as variable $D_s = 0, 1$ (1 for included)

Report estimated coverage as average of $D_s$ over $s$
:::

Can also report other characteristics of length distribution (e.g. quantiles)

::: {.footer}

For multivariate sets the metric is usually called *volume*

::: 
 

## Simulation Implementation {background="#00100F"}

### Completing Simulation Design {background="#43464B"}


#### Recap: Simulation Setting

Let's come back to our example of today. Already have

- DGP of variables (normal with different variances)
- Estimators: maximum likelihood
- Confidence interval to evaluate: based on asympotic normality of $\hat{\sigma}^2$

::: {.left-color}

Still need to choose remaining DGP parameters: mean $\mu$ and sample size $N$

::: 


#### Choosing the Remaining Parameters

#### Code Organization

Our simulation is quite small

### Implementing Results {background="#43464B"}



## Simulation Results {background="#00100F"}

#### Results Handling

Since our simulation is small, can just rerun any time

Then don't save the results

and just pass them directly to plottiing functions


## Recap and Conclusions {background="#00100F"}
 
#### Recap

<br>

In this lecture we 

- Discussed  

#### References {.allowframebreaks visibility="uncounted"}

::: {#refs}
:::
