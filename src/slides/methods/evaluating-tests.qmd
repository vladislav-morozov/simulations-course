---
title: "Evaluating Hypothesis Tests"
subtitle: "SUBTITLE"
author: Vladislav Morozov  
format:
  revealjs:
    include-in-header: 
      text: |
        <meta name="description" content=" (lecture note slides)"/> 
    width: 1150
    slide-number: true
    sc-sb-title: true
    incremental: true   
    logo: ../../themes/favicon.ico
    footer: "Evaluating Hypothesis Tests"
    footer-logo-link: "https://vladislav-morozov.github.io/simulations-course/"
    theme: ../../themes/slides_theme.scss
    toc: TRUE
    toc-depth: 2
    toc-title: Contents
    transition: convex
    transition-speed: fast
slide-level: 4
title-slide-attributes:
    data-background-color: "#3c165cff"
    data-footer: " "
filters:
  - reveal-header 
embed-resources: true
include-in-header: ../../themes/mathjax.html 
highlight-style: tango
open-graph:
    description: "  (lecture note slides)" 
---






## Introduction {background="#00100F"}
 
  
```{python}
import matplotlib.pyplot as plt
import numpy as np

from scipy.stats import chi2
BG_COLOR = "whitesmoke"
THEME_COLOR = "#3c165c"
```

### Lecture Info {background="#43464B"}

#### Learning Outcomes

This lecture is about evaluating hypothesis tests

<br>

By the end, you should be able to

 
- Capture 


#### References

<br>

::: {.nonincremental}

 
- SOmething

:::

### Motivating Example Question {background="#43464B"}

#### Setting: Joint Hypotheses
 
Often want to test <span class="highlight">joint hypotheses</span>: hypotheses that involve several statements about parameters at the same time:

<div class="left-color">
$$
\begin{aligned}
& H_0: \text{for all $k$ the statement $A_k$ is true} \quad \text{vs.} \\
&  H_1: \text{for at least some $k$ the statement $A_k$ is not true}
\end{aligned}
$$

</div>

<br>

Example: null that some coefficients are zero
$$
\begin{aligned}
H_0: \theta_k = 0, \quad k=1, \dots, p
\end{aligned}
$$

#### Motivating Question for Simulation

Two example approaches:

- With a simultaneous (joint) test (e.g. Wald/$F$, LM, LR)
- Testing each component separately (e.g. with a $t$-test) and combining the results (with adjusted $p$-values)

. . . 


<br>

Question of today:

<div class="left-color">

When do we generally use the first approach? 

</div>
 
#### Goals for Today:

How to answer this question? 

<br>

Today talk about

- What matters for comparing hypothesis tests
- How to simulate tests
- How to interpret results

## Theory Essentials for Hypothesis Testings {background="#00100F"}
 

### Definitions {background="#43464B"}



#### Basic Setup: Hypotheses

Suppose that we have a model with some parameters $\theta$ (of whatever nature)

<div class="left-color">

Two competing *hypotheses* (statements about parameters $\theta$)
$$
H_0: \theta\in \Theta_0 \text{  vs.  } H_1: \theta \in \Theta_1 
$$
for some non-intersecting $\Theta_0$ and $\Theta_1$

</div>

#### Examples of Hypotheses

Example: linear model of the form:

$$\small
Y_i  = \sum_{k=0}^{p} \beta_k X_i^{(k)}
$$

- Hypothesis on one parameter: $H_0: \beta_k \leq 0$ vs. $H_1: \beta_k >0$
- Hypothesis about many parameters: 
$$ \small
H_0: \beta_0= \dots = \beta_p =0 \quad \text{ vs. } H_1: \beta_k\neq 0 \text{ for some }k
$$

#### Definition of a Test

A test is a *decision rule*: you see the sample and then you decide in favor of $H_0$ or $H_1$


. . . 

<br>

Formally:

<div class="rounded-box">

::: {#def-vector-inference-test}

A test $T$ is a function of the sample $(X_1, \dots, X_N)$ to the space $\{ \text{Reject } H_0$,  $\text{Do not reject }H_0 \}$

:::

</div>




#### Power

<br>

Key property of a hypothesis test: 
<div class="rounded-box">

::: {#def-vector-inference-power}

The power function $\text{Power}_T(\theta)$ of the test $T$ is the probability that $T$ rejects if $\theta$ is the true parameter value:
$$
\text{Power}_T(\theta) = P(T(X_1, \dots, X_N)=\text{Reject }H_0|\theta)
$$

:::

</div>

 

#### Test Size

Maximal power under the null has a special name 
<div class="rounded-box">

::: {#def-vector-inference-size}

The <span class="highlight"> size </span> $\alpha$ of the test $T$ is 
$$
\alpha = \max_{\theta\in\Theta_0} \text{Power}_T(\theta)
$$

:::

</div>

In other words, the probability of falsely rejecting the null — <span class="highlight">type I error</span>


#### What Defines a Good Test? 

The best possible test has perfect detection:

- Never rejects under $H_0$
- Always reject under $H_1$

. . . 

<br>

Usually impossible in practice. Instead, we ask

- Not too much false rejection under $H_0$ (e.g. $\leq 5\%$ of the time)
- As much rejection as possible under $H_1$ 
 

#### Role of Size and Power


<div class="rounded-box">

Power function — key metric in comparing tests

</div>

<br>

::: {.nonincremental}

 

Give preference to tests that

- Control size correctly 
- Reject alternative more often (=use data more efficiently)

:::

### Tests and Test Statistics {background="#43464B"}

 
 
 


#### How Testing Works in General

<div class="left-color"> 

How do we construct a test/decision rule?

</div>

<br>

. . .

Basic approach:

1. Pick a "statistic" (=some known function of the data) that behaves "<span class="highlight">differently</span>" under $H_0$ and $H_1$
2. Is the observed value of the statistic <span class="highlight">compatible</span> with $H_0$? 
   - No $\Rightarrow$ reject $H_0$ in favor or $H_1$
   - Yes $\Rightarrow$ do not reject $H_0$






#### Measuring Compatibility with $H_0$

<div class="left-color">

Recall: compare with <span class="highlight">critical values</span> to measure compatibility with $H_0$

</div>

<br>

Critical values chosen to guarantee

- Exact size (when possible)
- Asymptotic size (otherwise) 

At least in the limit, the test should not falsely reject $H_0$ "too much"

::: {.footer}

The asymptotic size $\alpha$ of the test $T$ is $\alpha = \lim_{N\to\infty} \max_{\theta\in\Theta_0}  P(T(X_1, \dots, X_N)=\text{Reject }H_0|\theta)$

:::
 

#### Reminder: Main Classes of Statistics

- In principle, can pick any statistic. Some are more "standard"
- For testing hypotheses about coefficients, there are three main classes:
  - Wald statistics: need only *unrestricted* estimates 
  - Lagrange multiplier (LM): need *restricted* estimates 
  - Likelihood ratio (LR): need both
 

#### Example I: $t$-Test for $H_0: \theta_k=0$ vs. $H_1: \theta_k\neq 0$
 

Suppose that have estimator $\hat{\theta}_k$ such that
$$ \small
\sqrt{N}(\hat{\theta}_k-\theta_k)\xrightarrow{d} N(0, \avar(\hat{\theta}_k))
$$


Will base the test on the <span class="highlight">$t$-statistic</span>:
$$ \small
t = \dfrac{\hat{\theta}_k}{\sqrt{ \widehat{\avar}(\hat{\theta}_k)/N }  }
$$


#### Example I: Definition of $t$-Test  


We call the following the <span class="highlight">asymptotic size $\alpha$ $t$-test</span>:

<br>

<div class="rounded-box">

Let $z_{1-\alpha/2} = \Phi^{-1}(1-\alpha/2)$. Then

- Reject $H_0$ is $\abs{t}>z_{1-\alpha/2}$
- Do not reject $H_0$ is $\abs{t}\leq z_{1-\alpha/2}$


</div>

 

#### Example II: Wald Test for $H_0: \bR\btheta =\bc$ vs. $H_1: \bR\btheta \neq \bc$
 
Let $\btheta= (\theta_0, \theta_1, \dots, \theta_p$, $\bR$ some matrix, $\bc$ some vector.

Suppose that have estimator $\hat{\btheta}$ such that
$$ \small
\sqrt{N}(\hat{\btheta}-\btheta)\xrightarrow{d} N(0, \avar(\hat{\btheta}))
$$


Will base the test on the <span class="highlight">Wald statistic</span>:
$$ \small
W = N\left(  \bR\hat{\bbeta}-\bq   \right)'\left(\bR\widehat{\avar}(\bbeta)\bR'\right)^{-1}\left(  \bR\hat{\bbeta}-\bq   \right)
$$ 

#### Example II: Definition of Wald Test

We call the following the <span class="highlight">asymptotic size $\alpha$ Wald-test</span>:


<br>

<div class="rounded-box">

Let $c_{1-\alpha}$ solve $P(\chi^2_k\leq c_{1-\alpha})=1-\alpha$ where $k$ is the number of rows and rank of $\bR$. Then

- Reject $H_0$ if $W>c_{1-\alpha}$
- Do not reject $H_0$ if $W\leq c_{1-\alpha}$


</div>

#### Plot: PDF of $\chi^2_k$ and Rejection Region (Shaded)

```{python}


# Parameters for the chi-squared distribution
df = 5

# Generate the x values for the PDF
x_vals = np.linspace(0, 20, 1000)

# Compute the PDF values
pdf_vals = chi2.pdf(x_vals, df)

# Compute the 95th quantile
quantile_95 = chi2.ppf(0.95, df)

# Set up the figure and the axes
fig, ax = plt.subplots(figsize=(15, 6))
fig.patch.set_facecolor(BG_COLOR)
fig.patch.set_edgecolor(THEME_COLOR)
fig.patch.set_linewidth(5)

# Plot the PDF
ax.plot(x_vals, pdf_vals, label=f'PDF of $\\chi^2_k$ distribution', color=THEME_COLOR)

# Fill the area under the PDF to the right of the 95th quantile
ax.fill_between(x_vals, pdf_vals, where=(x_vals >= quantile_95), color='darkorange', alpha=0.3)

# Mark the 95th quantile
ax.axvline(quantile_95, color='red', linestyle='--', label="$c_{1-\\alpha}$")

# Set the labels and title 
ax.set_ylabel('Density') 
ax.legend(loc='upper right')
ax.set_ylim(0, 0.17)
ax.set_xlim(0, 20)
ax.set_xticklabels([])
ax.set_yticklabels([])
ax.set_facecolor(BG_COLOR)

# Show the plot
plt.show()

```
 
## Preparing Simulation: Joint vs. Multiple Tests {background="#00100F"}

### Choosing a Basic Scenario {background="#43464B"}


### Background: Joint and Multiple Test {background="#43464B"}



#### Formalizing The Question

#### 1



#### Multiple Test Approach

## Simulating Hypothesis Test Performance {background="#00100F"}
 

#### Technique: Reference Scenario

Today: trying to understand something 

Try to include a "reference" nice scenario

and vary something 



#### Reference Scenario: Simple Linear Model

Simple linear model:
$$
Y_i = \theta_0 + \theta_1 X_i^{(1)} + \theta_0 X_{i}^{(2)} + U_i
$$


. . . 

<br>

Very simple kind of joint hypothesis:
$$
H_0: \theta_1 = \theta_2 = 0
$$


#### Effects for DGP


#### Aside: On Code Structure

Will keep using the code structure developed in 

actually many DGPs from one class. Creation of multiple things — handled by `scenarios.py`

## Simulation Results {background="#00100F"}
 
#### 

Now have a larger array of simulation results. 

## Recap and Conclusions {background="#00100F"}
 
#### Recap

<br>

In this lecture we 

- Discussed  




#### References {.allowframebreaks visibility="uncounted"}

::: {#refs}
:::
