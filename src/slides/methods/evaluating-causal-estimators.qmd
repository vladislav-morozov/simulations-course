---
title: "Evaluating Causal Estimators"
subtitle: "SUBTITLE"
author: Vladislav Morozov  
format:
  revealjs:
    include-in-header: 
      text: |
        <meta name="description" content="Learn how to evaluate  (lecture note slides)"/> 
    width: 1150
    slide-number: true
    sc-sb-title: true
    incremental: true   
    logo: ../../themes/favicon.ico
    footer: "Evaluating Causal Estimators"
    footer-logo-link: "https://vladislav-morozov.github.io/simulations-course/"
    theme: ../../themes/slides_theme.scss
    toc: TRUE
    toc-depth: 2
    toc-title: Contents
    transition: convex
    transition-speed: fast
slide-level: 4
title-slide-attributes:
    data-background-color: "#3c165cff"
    data-footer: " "
filters:
  - reveal-header 
embed-resources: true
include-in-header: ../../themes/mathjax.html 
highlight-style: tango
open-graph:
    description: "Learn how to evaluate c (lecture note slides)" 
---






## Introduction {background="#00100F"}
  

### Lecture Info {background="#43464B"}

#### Learning Outcomes

This lecture is about evaluating causal estimators

<br>

By the end, you should be able to

 
- Describe k 
- Use simulations as a tool for constructing (counter)examples
 


#### References 
  
::: {.nonincremental}

Intros to causal inference:

- @Cunningham2021CausalInferenceMixtape (more basic)
- @Morgan2014CounterfactualsCausalInference (more general with many discussions)

On fixed effect estimation:

- [My slides](https://vladislav-morozov.github.io/econometrics-2/slides/panel/fe.html) 
- Chapter 17 in @Hansen2022Econometrics

:::
 


## Motivation: Fixed Effects and Simulations as Counterexamples {background="#00100F"}
 


### Background on Fixed Effect Estimation {background="#43464B"}

#### Setting: Panel Data

Suppose that we have data on

- Some outcome $Y_{it}$
- Some treatment $\bX_{it}$ (possibly vector)

. . . 

::: {.left-color}

Interested in causal effect of $\bX_{it}$  on $Y_{it}$

:::

<br>


Data is <span class="highlight">panel</span>: 

- Two dimensions ($i$ and $t$)
- E.g. units $i=1, \dots, N$ over time $t=1, \dots, T$



#### Reminder: Random Intercept/Fixed Effect Estimation

::: {.left-color}

One way to estimate effects of treatment on $Y_{it}$ is using <span class="highlight">random intercept/fixed effect</span> estimators

:::

Simple example: one-way FE estimator:

1. Construct
$$\small 
\tilde{Y}_{it} = Y_{it} - \dfrac{1}{T}\sum_{s=1}^T Y_{is}, \quad \tilde{\bX}_{it} = \bX_{it} - \dfrac{1}{T}\sum_{s=1}^T \bX_{is},
$$

2. The one-way FE estimator is the  OLS estimator in regression of $\tilde{Y}_{it}$ on $\tilde{\bX}_{it}$



#### Causal Model Underlying FE


::: {.left-color}

Remember: properties of causal estimator only meaningful if one specifies an underlying causal model

:::

. . .  

For one-way FE estimator: typical setting is linear <span class="highlight">potential outcomes</span> model

$$
Y_{it}^{\bx} = \alpha_i + \bbeta'\bx + U_{it}
$$ {#eq-fe-causal-model}

- $\alpha_i$ --- the "random intercept"/unit FE
- $\beta$ --- common treatment effect of $x$ 
 
#### Properties Under Random Intercept Model

::: {.rounded-box}

Under


- FE causal model ([-@eq-fe-causal-model])
- Strict exogeneity: $\E[U_{it}|X_{i1}, \dots, X_{iT}]=0$
 

the one-way random intercept estimator $\hat{\bbeta}^{FE}$ satisfies
$$
\begin{aligned}
 \E[\hat{\bbeta}^{FE}]  & = \bbeta, \\
 \sqrt{N}(\hat{\bbeta}^{FE} - \bbeta) & \xrightarrow{d} N(0, \avar(\hat{\bbeta}^{FE}))
\end{aligned}
$$


:::


### Fixed Effect Estimators and Heterogeneous Coefficients  {background="#43464B"}

#### Discussion of FE Estimator

- Typical motivation: "controlling unobserved heterogeneity"
- Unobserved heterogeneity:
    - Unit-specific effects $\alpha_i$
    - Can also time effects $\gamma_t$ and other versions

::: {.left-color}

If model correctly specified, suitable FE estimator will recover $\bbeta$

::: 

#### A More Realistic Causal Model
 
But model ([-@eq-fe-causal-model]) not internally consistent:

::: {.nonincremental}

- Why unobserved heterogeneity only in intercepts $\alpha_i$?
- Why not <span class="highlight">heterogeneous treatment effects</span>?

:::

. . . 

More realistic to assume causal model
$$
Y_{it}^{\bx} = \alpha_i + \bbeta_{i}'\bx + U_{it}
$$ {#eq-causal-hetero}
Now $\bbeta_i$ --- also unit-specific

::: {.footer}

Can also consider even more general models with $\bbeta_{it}$

:::

#### Question: What Does the FE Estimator Do?

Suppose model ([-@eq-causal-hetero]) is true, but we still apply $\hat{\bbeta}^{FE}$

::: {.left-color}

What is $\hat{\bbeta}^{FE}$ actually estimating?

:::

<br>

- Important to separate estimator from underlying causal model!
- Can carry out FE estimation even if true model is not random intercept
 
#### Estimand of FE Estimator Under Model  ([-@eq-causal-hetero])

Can show that
$$ \small
\hat{\bbeta}^{FE} \xrightarrow \E\left[ \left( \E\left[ \tilde{\bX}_i'\tilde{\bX}_i \right]\right)^{-1} \tilde{\bX}'_i\bbeta_i \right]
$$ {#eq-fe-limit-hetero}
where $\tilde{\bX}_i'$ --- matrix with $\tilde{\bX}_{it}'$ as rows

- FE estimator  $\xrightarrow{p}$ weighted average of individual effects
- In general
$$ \small
\mathrm{plim}_{N\to\infty} \hat{\bbeta}^{FE} \neq \E[\bbeta_i]
$$

#### Simulation Question of Today
 

::: {.rounded-box}

It is possible that "controlling for heterogeneity"  with FE estimators <span class="highlight">can lead to more bias</span>  than not doing anything about heterogeneity?

::: 

- This matters because FE estimators are used *a lot*
- Well-suited for simulations:
    - Theory hard due to $\hat{\bbeta}^{FE}$ depending on transforms and inverses of $\bX_{it}$ 
    - In simulations: can try to find a single example numerically


## Theory Essentials for Evaluating Causal Estimators {background="#00100F"}
 
#### Potential Outcomes Framework

- Key feature of causal settings: some causal process
- Typically expressed using <span class="highlight">potential outcomes</spam>

. . . 

::: {.left-color}

$$
Y_i^x = \phi(x, U_i)
$$
= "If unit $i$ with unobserved characteristics $U_i$ receives treatment $x$, their outcome is $Y_i^x$"

:::

$\phi$ may be known of (fully/partially) unknown

::: {.footer}

Same type of approach can be used with panel or time series settings. Also can consider settings where treatment of others matters

:::

#### Treatment Effects

Potential outcomes allow defining <span class="highlight">causal effects</spam>: 

::: {.left-color}

Causal effect of moving from treatment $\bx_1$ to $\bx_2$ for unit $i$ is defined as
$$
\phi(\bx_2, U_i) - \phi(\bx_1, U_i)
$$

:::

- Typically different between units (because of different values of $U_i$)
- Intuition: "exogenously/dictatorially" changing $\bx$ of unit $i$ --- difference in outcome attributable only to change in $\bx$

#### Causal Parameters of Interest

Usually interested in some <span class="highlight">distributional features</spam> of causal effects:

- Average effects
- Variance of effects (or higher-order moments)
- Distribution of causal effects
- Differences between distributions of potential outcomes (distributional/quantile treatment effects)


Sometimes can learn individual treatment effects themselves


#### Settings for Studying Causal Estimators

<br>

Two scenarios for studying causal estimators:

- How well in performs in setting it was designed for (where it is guaranteed to consistently estimate the parameter of interest)
- Robustness: how well/badly it performs in settings they are not designed for

#### Relevance For Simulations

In simulations:

- Always need to fully specify $\phi(\cdot, \cdot)$ 
- Sample = data you would observe in practice (e.g. $Y_i$ and $\bX_i$, not $U_i$)
- True target parameters need to be computed from $\phi(\cdot, \cdot)$ and distribution of $U_i$



#### Metrics of Interest
 

Three metrics you typically see when evaluating causal estimators:

::: {.left-color}

- Bias
- Variance
- Full sampling distribution

:::

. . .
 
Distribution: usually for inference purposes (good normal approximation $\Rightarrow$ good performance of natural asymptotic intervals)



## Specifying the Simulations {background="#00100F"}
 
#### Recap of Simulation Setting

So far: 

- Causal model of form
$$
Y_{it}^{\bx} = \alpha_i + \bbeta_i'\bx + U_{it} 
$$
- Estimator to study: one-way FE estimator (the one that eliminates the $\alpha_i$)
- Question is robustness:

::: {.left-color}

Can FE estimator be somehow worse than not eliminating $\alpha_i$ at all?

:::

#### Things To Specify

<br>

- Need to finish specifying DGP (coefficients process, treatments, $U_{it}$)
- What "worse" means
- What "not eliminating $\alpha_i$" means
- Causal parameter of interest

#### Simplifying Setting

::: {.left-color}

Again: want simplest possible example

:::

<br>

Specify model in form
$$
\begin{aligned}
Y_{it} & = \alpha_i + (\beta + \alpha_i) X_{it} + Y_{it}, \quad i=1, \dots, N, \quad t=1, 2
\end{aligned}
$$ 

- Shortest genuine panel with $T=2$
- Coefficients controlled by $\alpha_i$

#### Specifying Coefficient Distribution
 
Now just need to specify $\beta$ and distribution of $\alpha_i$ 

<br> 

- Set $\alpha_i \pm 1$ with equal probability
- Set $\beta=-0.25$ ($\Rightarrow \E[\beta_i]=-0.25$)

. . .

$\Rightarrow$ two types of units: 

- 50% with $\beta_i = -1.25$ 
- 50% with $\beta_i=0.75$


#### Estimators Compared

Obvious that we need to include one-way random intercept/FE estimator

<br>

. . .

And

- Need something that does not eliminate $\alpha_i$
- Simple baseline: OLS 
- OLS: just regressing $Y_{it}$ on $(1, X_{it})$ without any transformations 
 
#### Causal Parameter of Interest

::: {.left-color}

Remember: causal parameter must be specified based on the causal model, not on the estimator

:::

In our case

- FE estimator often "justified" with the excuse that it still estimates "average effects"
- "Average effects" often understood in the sense of ATE, not the weighted average ([-@eq-fe-limit-hetero])
- $\Rightarrow$ <span class="highlight">parameter of interest is $\E[\beta_i]$ </span> --- can be used to compute ATE of any change in $x$

#### Metric and Goal

Good metric: bias of FE and OLS estimators for $\E[\beta_i]$ 

<br>

. . . 

Want a dramatic example for things going wrong the FE vis-Ã -vis $\E[\beta_i]$

- Want OLS (doing nothing about heterogeneity) to be unbiased for $\E[\beta_i]$
- Want FE (doing something, but wrong) to have the wrong sign 

#### How To Specify DGPs 

Good place to start looking --- moment conditions that characterize limits of estimators

- OLS consistent if
$$ \small
\mathbb{E}[X_{it}(\alpha_i + \alpha_i X_{it}+ U_{it})]  = 0, \quad t=1, 2
$$ {#eq-moment-ols}
- FE inconsistent (why?) if
$$  \small
 \mathbb{E}[(X_{i2}- X_{i1})(\alpha_i (X_{i2}- X_{i1})+ U_{it})] \neq 0 
$$ {#eq-moment-fe}

Distribution of $(X_{it}, U_{it})$ must be same for both estimators

#### Distribution for $U_{it}$

Moment conditions tell us

- Both estimators have "~same dependence" on properties of $U_{it}$
- $\Rightarrow$ differences in bias likely shouldn't depend on $U_{it}$ much
- $\Rightarrow$ can just make a very simple assumption again


::: {.left-color}

Assume that $U_{it}$ is standard normal

:::
 
#### Covariate Distribution

- Can try simple normal distributions again
- Different distributions given different $\alpha_i$ --- some sort of implicit (self-)selection mechanism
$$  \small
\begin{aligned}
\begin{pmatrix} X_{i1} \\ X_{i2} \end{pmatrix}\Bigg| \alpha_i = + 1  & \sim N\left( \begin{pmatrix} \mu_{1+} \\ \mu_{2+} \end{pmatrix}, \begin{pmatrix} \sigma_{1+}^2 & \rho_+ \sigma_{1+} \sigma_{2+} \\ \rho_+ \sigma_{1+} \sigma_{2+} & \sigma_{2+}^2 \end{pmatrix} \right)  \\
\begin{pmatrix} X_{i1} \\ X_{i2} \end{pmatrix}\Bigg| \curl{\alpha_i = - 1}  & \sim N\left( \begin{pmatrix} \mu_{1-} \\ \mu_{2-} \end{pmatrix}, \begin{pmatrix} \sigma_{1-}^2 & \rho_- \sigma_{1-} \sigma_{2-} \\ \rho_- \sigma_{1-} \sigma
_{2-} & \sigma_{2-}^2 \end{pmatrix} \right)
\end{aligned}
$$

::: {.footer}

In some settings import to explicitly model selection into treatment

:::

#### Finding Parameters 

- Now have full distribution of $(\alpha_i, X_i, U_i)$
- $\Rightarrow$ can compute expectations in ([-@eq-moment-ols])-([-@eq-moment-fe])!
- Can now solve as system of equations for the $\mu$s, $\rho$s, and $\sigma$s

. . . 

::: {.left-color}

Will solve numerically as part of DGP generation

:::

## Simulation Implementation {background="#00100F"}

#### 

a


#### Code Organization

#### Creating DGPs

On import `scenarios.py` will find 


::: {.footer}

Try adding more target values and comparing distributions

:::

## Results {background="#00100F"}
 
####

## Recap and Conclusions {background="#00100F"}
 
#### Recap

<br>

In this lecture we 

- Reviewed  


#### References {.allowframebreaks visibility="uncounted"}

::: {#refs}
:::
