---
title: "Writing Good Simulation Code"
subtitle: "How to Structure Code: From Monolithic to Modular Design"
author: Vladislav Morozov  
format:
  revealjs:
    include-in-header: 
      text: |
        <meta name="description" content="  (lecture note slides)"/> 
    width: 1150
    slide-number: true
    sc-sb-title: true
    incremental: true   
    logo: ../../themes/favicon.ico
    footer: "Why Simulate and General Principles"
    footer-logo-link: "https://vladislav-morozov.github.io/simulations-course/"
    theme: ../../themes/slides_theme.scss
    toc: TRUE
    toc-depth: 2
    toc-title: Contents
    transition: convex
    transition-speed: fast
slide-level: 4
title-slide-attributes:
    data-background-color: "#3c165cff"
    data-footer: " "
filters:
  - reveal-header 
embed-resources: true
include-in-header: ../../themes/mathjax.html 
highlight-style: tango
open-graph:
    description: " (lecture note slides)" 
---






## Introduction {background="#00100F"}
 
  

### Lecture Info {background="#43464B"}

#### Learning Outcomes

This lecture is  

<br>

By the end, you should be able to


- Discuss  

#### References

::: {.nonincremental}

Statistics:

- Chapter 4 of @Hansen2022Econometrics for OLS
- Chapter 14 of @Hansen2022Econometrics for time series basics

Programming

- Chapter 26-27 of @Lutz2025LearningPythonPowerful on OOP in Python

:::


### Simulation Setting {background="#43464B"}


#### Context: Bias of OLS Estimator

Consider the simple causal linear model:

$$
Y_{t}^x = \beta_0 + \beta_1 x + U_t, \quad t=1, \dots, T
$$
$Y_t^x$ — potential outcome under $x$ for observation $t$

<br>

Basic econometrics tells us that OLS estimator in regressing $Y_t$ on $(1, X_t)$ is

- Unbiased if $\E[U_t|X_1, \dots, X_T] = 0$
- Biased otherwise 

#### Why Care About Bias?

<div class="left-color">

Why should a user of OLS care about this bias?  
 
</div>


<br>

 
If bias is big, can lead to

- Improperly centered confidence intervals
- Wrong sign of point estimate
 
<br>

$\Rightarrow$ both can lead to incorrect policy conclusions
 
#### Today's Questions

::: {.nonincremental}

<br>

<div class="rounded-box">

- How big is the bias?
- How to think about and structure simulations in general?
  
 
</div>

:::



<br> 

Today — a showcase of 

- Our three-step simulation anatomy
- A sketch for extensible simulation design — foundation for later
 

## Setting Out Simulation Goals {background="#00100F"}
 

 

### Choosing Context {background="#43464B"}



#### Why Not Theory?

Theory not fully satisfactory: expression for bias depends on the DGP for $(X_t, U_t)$:
$$
\E[\hat{\bbeta}] - \bbeta= \E\left[ (\bW'\bW)^{-1}\bW'\bU \right]
$$
where $\bW$ — $T\times 2$ with $t$th row given by $(1, X_t)$


- @Bao2007SecondOrderBiasMean: asymptotic order $O(1/T)$
- Unclear if actual magnitude "important in practice"


#### Why Not Use Real Data?

 
Empirical data validation not an option both in causal and predictive settings:

- Can never measure true bias even if believe in linear model
- In predictive settings: don't even care about $\hat{\bbeta}$, only about predicted $\hat{Y}_t$

. . .

<br>


<div class="left-color">

Have to recur to simulations

</div>

#### Simulation Requirements



<br>

Recall that simulations should be 

- Realistic: need to think about relevant real world scenario to emulate

- Targeted: 
    - Be specific in terms of target metrics
    - Focus in DGPs that cause differences in target metrics
 
#### Choosing Scenario: Time Series

As an example, we care about <span class="highlight">time series</span>

<br>

What's relevant?

- Possibility of dependence across time
- Different strength of dependence
- Different lengths of time series
- (More advanced): data drift/time-varying DGP

. . . 

We'll include the first three

#### Metrics

For simplicity, we will consider just one explicit metric:

<div class="rounded-box">

Our metric: absolute bias of OLS estimator

</div>


<br> 


Other metrics:

- Coverage of CIs based on the OLS estimator
- Proportion of incorrect signs ($\mathrm{sgn}{\hat{\beta}_1}\neq \mathrm{sgn}(\beta_1)$)



### Specifying DGPs {background="#43464B"}

#### The Problem of DGP Choice

#### Static vs. Dynamic

#### Sample Size

#### DGP for Innovations and Exogenous $X_t$

#### 

$T$


<div class="left-color">

Here: talk in a very stylized manner. Later — more on

</div>


## Naïve Implementation {background="#00100F"}
 

 

### Basic Function {background="#43464B"}

#### Learning Outcomes

This lecture is  

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def run_ols_simulation(n_sim=1000, n_obs=100, beta0=0, beta1=1, rho=0, dgp_type="strict"):
    """
    Monolithic function to simulate OLS bias under two DGPs.

    Args:
        n_sim: Number of simulations
        n_obs: Number of observations per simulation
        beta0: Intercept
        beta1: Slope coefficient
        rho: AR(1) coefficient (only used if dgp_type="ar1")
        dgp_type: "strict" (strict exogeneity) or "ar1" (AR(1) errors)
    """
    results = []

    for _ in range(n_sim):
        if dgp_type == "strict":
            # Strict exogeneity DGP
            x = np.random.normal(size=n_obs)
            epsilon = np.random.normal(size=n_obs)
            y = beta0 + beta1 * x + epsilon
        elif dgp_type == "ar1":
            # AR(1) DGP
            u = np.zeros(n_obs)
            for t in range(1, n_obs):
                u[t] = rho * u[t-1] + np.random.normal()
            x = np.random.normal(size=n_obs)
            y = beta0 + beta1 * x + u
        else:
            raise ValueError("dgp_type must be 'strict' or 'ar1'")

        # OLS estimation (manual for clarity)
        X = np.column_stack([np.ones(n_obs), x])
        beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y
        results.append(beta_hat[1])  # Store slope estimate

    # Plot results
    plt.figure(figsize=(10, 6))
    plt.hist(results, bins=30, edgecolor="k", alpha=0.7)
    plt.axvline(beta1, color="red", linestyle="--", label="True $\\beta_1$")
    plt.title(f"Distribution of OLS Estimates ({dgp_type} DGP, ρ={rho})")
    plt.xlabel("Estimated $\\beta_1$")
    plt.ylabel("Frequency")
    plt.legend()
    plt.show()

    return results

# Example usage:
strict_results = run_ols_simulation(dgp_type="strict")
ar1_results = run_ols_simulation(dgp_type="ar1", rho=0.7)

```

## A More Robust Implementation {background="#00100F"}
 
  

### Further Improvements {background="#43464B"}

#### Unifying 

This lecture is  

#### How Much Information


#### Better DGPs

attached to some empirical dataset


## Recap and Conclusions {background="#00100F"}
 
#### Recap

<br>

In this lecture we 
 

#### Next Questions

<br>

Now  
#### References {.allowframebreaks visibility="uncounted"}

::: {#refs}
:::
