{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Good Simulation Code II: Modular Approach\"\n",
        "subtitle: \"A Flexible and Extensible Design\"\n",
        "author: Vladislav Morozov  \n",
        "format:\n",
        "  revealjs:\n",
        "    include-in-header: \n",
        "      text: |\n",
        "        <meta name=\"description\" content=\"How to write good Monte Carlo simulation code in data science: modular OOP design with DGP and simulation classes; worked OLS example (lecture note slides)\"/> \n",
        "    width: 1150\n",
        "    slide-number: true\n",
        "    sc-sb-title: true\n",
        "    incremental: true   \n",
        "    logo: ../../themes/favicon.ico\n",
        "    footer: \"Code Design II: A Modular Approach\"\n",
        "    footer-logo-link: \"https://vladislav-morozov.github.io/simulations-course/\"\n",
        "    theme: ../../themes/slides_theme.scss\n",
        "    toc: TRUE\n",
        "    toc-depth: 2\n",
        "    toc-title: Contents\n",
        "    transition: convex\n",
        "    transition-speed: fast\n",
        "slide-level: 4\n",
        "title-slide-attributes:\n",
        "    data-background-color: \"#3c165cff\"\n",
        "    data-footer: \" \"\n",
        "filters:\n",
        "  - reveal-header \n",
        "embed-resources: true\n",
        "include-in-header: ../../themes/mathjax.html \n",
        "highlight-style: tango\n",
        "open-graph:\n",
        "    description: \"How to write good Monte Carlo simulation code in data science: modular OOP design with DGP and simulation classes; worked OLS example (lecture note slides)\" \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Introduction {background=\"#00100F\"}\n",
        " \n",
        "  \n",
        "\n",
        "### Lecture Info {background=\"#43464B\"}\n",
        "\n",
        "#### Learning Outcomes\n",
        "\n",
        "This lecture is about a modular approach to designing simulation code\n",
        "\n",
        "<br>\n",
        "\n",
        "By the end, you should be able to\n",
        "\n",
        " \n",
        "- Refactor code into modular reusable classes\n",
        "- Compose DGPs and estimators into simulations\n",
        "- Understand how modularity leads to clearer, more extensible code  \n",
        "\n",
        "#### References\n",
        "\n",
        "::: {.nonincremental}\n",
        "\n",
        "Statistics:\n",
        "\n",
        "- Chapter 4 of @Hansen2022Econometrics for OLS\n",
        "- Chapter 14 of @Hansen2022Econometrics for time series basics\n",
        "\n",
        "Programming\n",
        "\n",
        "- Chapter 2-3 of @Hillard2020PracticesPythonPro on basics of design\n",
        "- Chapter 26-27 of @Lutz2025LearningPythonPowerful on OOP in Python\n",
        "\n",
        ":::\n",
        "\n",
        " \n",
        "\n",
        "### Reminder: Simulation Setting {background=\"#43464B\"}\n",
        "\n",
        "\n",
        "#### Reminder: Studying OLS Bias\n",
        "\n",
        "This time: continue studying <span class=\"highlight\">bias of OLS estimator</span> in simple linear model:\n",
        "\n",
        "$$\n",
        "Y_{t} = \\beta_0 + \\beta_1 X + U_t, \\quad t=1, \\dots, T\n",
        "$$ \n",
        "<br>\n",
        "\n",
        "Metric of interest: absolute bias\n",
        "\n",
        "$$\n",
        "\\text{Bias}(\\hat{\\beta}_1) = \\E[\\hat{\\beta}_1] - \\beta_1\n",
        "$$\n",
        "\n",
        "\n",
        "#### Reminder: Static and Dynamic DGPs \n",
        "\n",
        "\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"46%\"}\n",
        "\n",
        " \n",
        "**Static**:\n",
        "\n",
        "$$  \\small\n",
        "Y_{t} = \\beta_0 + 0.5 X_{t} + U_{t}\n",
        "$$\n",
        "\n",
        "Covariate $X_t$ independent from $U_t$ and over time\n",
        "\n",
        ":::\n",
        "\n",
        "  \n",
        "::: {.column width=\"8%\"} \n",
        "\n",
        ":::\n",
        "\n",
        "::: {.column width=\"46%\"} \n",
        "  \n",
        "**Dynamic**:\n",
        "\n",
        "$$ \\small\n",
        "Y_{t} = \\beta_0 + \\beta_1 Y_{t-1} + U_{t}\n",
        "$$\n",
        "\n",
        "Dependence: $\\beta_1$ value\n",
        "\n",
        "$$  \\small\n",
        "\\beta_1 \\in \\curl{0, 0.5, 0.95}\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "- One DGP per $U_t, X_t, Y_0$: each $N(0, 1)$\n",
        "- $T=50, 200$ \n",
        "\n",
        "#### Reminder: Current State of Simulation\n",
        "\n",
        "Last time: implemented things with a basic function\n"
      ],
      "id": "b3da78f1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "id": "2dc79488",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
        "plt.rcParams[\"font.sans-serif\"] = [\"Arial\"]\n",
        "\n",
        "BG_COLOR = \"whitesmoke\"\n",
        "THEME_COLOR = \"#3c165c\""
      ],
      "id": "eab860a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true \n",
        "def simulate_ols(\n",
        "    n_sim: int = 1000,\n",
        "    n_obs: int = 50,\n",
        "    beta0: float = 0.0,\n",
        "    beta1: float = 0.5,\n",
        "    seed: int = 1,\n",
        "    dgp_type: str = \"static\",\n",
        ") -> list[float]:\n",
        "    \"\"\"Simulates OLS estimation for static or AR(1) DGP.\n",
        "    Args:\n",
        "        n_sim (int): Number of simulations to run. Defaults to 1000.\n",
        "        n_obs (int): Number of observations per simulation. Defaults to 100.\n",
        "        beta0 (float): True intercept value. Defaults to 0.\n",
        "        beta1 (float): True slope coefficient. Defaults to 0.5\n",
        "        seed (int): random number generator seed. Defaults to 1.\n",
        "        dgp_type (str): Type of DGP: \"static\" or \"ar1\". Defaults to \"static\".\n",
        "\n",
        "    Returns:\n",
        "        list[float]: List of errors of beta1 estimates for each simulation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create container to store results\n",
        "    results_ols_errors = []\n",
        "\n",
        "    # InitializeRNG\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    # Core simulation loop\n",
        "    for _ in range(n_sim):\n",
        "        # 1. Draw data\n",
        "        if dgp_type == \"static\":\n",
        "            x = rng.normal(size=n_obs)\n",
        "            u = rng.normal(size=n_obs)\n",
        "            y = beta0 + beta1 * x + u\n",
        "        elif dgp_type == \"ar1\":\n",
        "            y = np.zeros(n_obs + 1)\n",
        "            u = rng.normal(size=n_obs + 1)\n",
        "            y[0] = beta0 + u[0]\n",
        "            for t in range(1, n_obs + 1):\n",
        "                y[t] = beta0 + beta1 * y[t - 1] + u[t]\n",
        "            # Use the last n_obs elements of y as and the first n_obs as x\n",
        "            x = y[:-1]  # x is y lagged (n_obs elements)\n",
        "            y = y[1:]  # y[1:] is the dependent variable (n_obs elements)\n",
        "        else:\n",
        "            # Handle the case of giving the wrong DGP value\n",
        "            raise ValueError(\"Invalid DGP choice\")\n",
        "\n",
        "        # 2. Run OLS estimation\n",
        "        W = np.column_stack([np.ones(n_obs), x])\n",
        "        beta_hat = np.linalg.inv(W.T @ W) @ W.T @ y\n",
        "\n",
        "        # 3. Compute error\n",
        "        results_ols_errors.append(beta_hat[1] - beta1)\n",
        "\n",
        "    return results_ols_errors"
      ],
      "id": "08b5d930",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Problem: How To Expand Simulations?\n",
        " \n",
        "\n",
        "What if we want to <span class=\"highlight\">expand our simulations</span>?\n",
        "\n",
        "- More distributions (e.g. heavier tails for innovations, different $X$)\n",
        "- Different models (not necessarily $Y_t = \\beta_0 + \\beta_1 X_t + U_t$)\n",
        "\n",
        "<br>\n",
        "\n",
        ". . .\n",
        "\n",
        "Function approach is <span class=\"highlight\">difficult to expand</span>: would have to keep adding components and selectors to `simulate_ols()`\n",
        "\n",
        "\n",
        "#### This Lecture: Dealing With Complexity\n",
        "\n",
        "\n",
        "Today: dealing with <span class=\"highlight\">design</span>\n",
        "\n",
        "- Untangling the different components of simulation\n",
        "- Learning a more modular structure\n",
        "- Understanding the why of it\n",
        " \n",
        "\n",
        "## Towards a Modular Design {background=\"#00100F\"}\n",
        " \n",
        "\n",
        "### Identifying Component Blocks in Code {background=\"#43464B\"}\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "#### A Step Back: What Are We Doing?\n",
        "\n",
        "There are three code tasks:\n",
        "\n",
        "1. *Data generation*: draw data from a DGP\n",
        "2. *Estimation*: apply an estimator to the data\n",
        "3. *Orchestration*: run the above many times and collect results\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "For now things are all jumbled up and hardcoded  by `simulate_ols()`  — <span class=\"highlight\">monolithic design</span>\n",
        "\n",
        "\n",
        "#### Why Should The Simulation Loop Care? \n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "The simulation loop shouldn't need to know:\n",
        "\n",
        "- How data is generated (e.g., AR(1) vs. static)\n",
        "- How estimation works (e.g., OLS vs. IV)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "</div> \n",
        "\n",
        "It only needs to:\n",
        "\n",
        "- Get data from *something* (DGP)\n",
        "- Pass data to *something* (estimator)\n",
        "- Repeat and store results\n",
        "\n",
        "#### Why Should the Estimator and DGP Care?\n",
        "\n",
        "Same logic goes for DGP: it shouldn't care\n",
        "\n",
        "- Whether it's going to be used one time or many times in a loop\n",
        "- About how the estimator uses its data after\n",
        "\n",
        ". . .\n",
        "\n",
        "Likewise, the estimator:\n",
        "\n",
        "- Doesn't need details of the loop\n",
        "- Doesn't need to know how the `y` and `x` are created, just their form\n",
        "\n",
        "#### Conclusion: Components\n",
        "\n",
        "Overall: identified three logical units in code\n",
        "\n",
        ". . . \n",
        "\n",
        "\n",
        "<br> \n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "\n",
        "\n",
        "These units should be more or less independent (<span class=\"highlight\">loosely coupled</span>) \n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "E.g.: \n",
        "\n",
        "- Changing DGP details should not affect loop, if loop can still sample in the same way\n",
        "- Can also then swap or add more components easily\n",
        "\n",
        "### Some Design Concepts {background=\"#43464B\"}\n",
        "\n",
        "\n",
        "\n",
        "#### Background: Separation of Concerns\n",
        "\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "\n",
        "Key in clear code: divide various behavious into small, manageable pieces\n",
        "\n",
        "\n",
        "</div> \n",
        "\n",
        "\n",
        "Best way to divide — <span class=\"highlight\">by concern</span>. This:\n",
        "\n",
        "- Reduces complexity (each part does one thing well)\n",
        "- Improves reusability (swap DGPs/estimators without rewriting everything)\n",
        "- Makes collaboration easier (different people can work on different parts)\n",
        "\n",
        "#### Interfaces: Glue Between Components\n",
        "\n",
        "\n",
        "Simulation runner only needs to know how to <span class=\"highlight\">interface</span> with DGP and estimator:\n",
        "\n",
        "- DGP interface: Must provide a method like `sample(n_obs, seed)`\n",
        "- Estimator interface: Must provide a method like `fit(X, y)`\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "\n",
        "As long as a DGP/estimator implement given interface, simulation runner can use it\n",
        "\n",
        " <span class=\"highlight\">Their implementation details do not matter to runner</span>\n",
        "\n",
        "</div> \n",
        "\n",
        "\n",
        "#### Background: Interfaces\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Interfaces are like contracts\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "- DGP promises to give valid data if `sample()` is called \n",
        "- Estimator promises to give suitable coefficients if `fit()` is called \n",
        "\n",
        ". . .\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "\n",
        "Benefit: You can add new DGPs/estimators without touching the simulation runner!\n",
        "\n",
        "</div>\n",
        "\n",
        " \n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "You likely familiar with this from `statsmodels` or `scikit-learn`: always having `fit()` for all estimators and algorithms\n",
        "\n",
        ":::\n",
        "\n",
        "#### DGPs Encapsulate Their Logic\n",
        "\n",
        "Each DGP encapsulates its own logic:\n",
        "\n",
        "- AR(1) DGP handles its own loops, initial conditions, etc.\n",
        "- Static DGP just draws IID data.\n",
        "\n",
        "<br>\n",
        "\n",
        "The outside world only sees the `sample()` method that returns a sample of `X` and `y` \n",
        "\n",
        "\n",
        "## Implementation {background=\"#00100F\"}\n",
        " \n",
        "### DGP and Estimator Classes {background=\"#43464B\"}\n",
        "\n",
        "#### Approach: Classes\n",
        "\n",
        "Now want implementation with these good properties (separation of concerns, loose coupling, encapsulation)\n",
        " \n",
        "\n",
        ". . .\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Will capture required logic with appropriate <span class=\"highlight\">classes</span>\n",
        "\n",
        "</div>\n",
        "\n",
        "- Going OOP allows us to view DGPs, estimators, and simulations as objects: \n",
        "  - Each will have some appropriate data and some logic for doing something with that data\n",
        "  - Different objects can interact using that logic\n",
        "- Simulation runner can  <span class=\"highlight\">compose</span> DGPs and estimators\n",
        "\n",
        "\n",
        "#### What Attributes and Methods Do Our Classes Need?\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "To define a class need to choose what data and functions its instances contain\n",
        "\n",
        "</div>\n",
        "\n",
        "- DGPs need to:\n",
        "  - Know their true `beta1` (e.g. for bias computation)\n",
        "  - Offer samples with given number of points from DGP-specific distribution\n",
        "- Estimator needs to:\n",
        "  - Compute `beta1_hat` based on data\n",
        "  - Remember computed `beta1_hat` \n",
        "  \n",
        "#### Example: Static DGP Class\n"
      ],
      "id": "1bca1f63"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "class StaticNormalDGP:\n",
        "    \"\"\"A data-generating process (DGP) for a static linear model\n",
        "\n",
        "    Attributes:\n",
        "        beta0 (float): Intercept term.\n",
        "        beta1 (float): Slope coefficient.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, beta0: float = 0.0, beta1: float = 0.5) -> None:\n",
        "        \"\"\"Initializes the DGP with intercept and slope.\n",
        "\n",
        "        Args:\n",
        "            beta0 (float): Intercept term. Defaults to 0.0.\n",
        "            beta1 (float): Slope coefficient. Defaults to 1.0.\n",
        "        \"\"\"\n",
        "        self.beta0: float = beta0\n",
        "        self.beta1: float = beta1\n",
        "\n",
        "    def sample(\n",
        "        self, n_obs: int, seed: int | None = None\n",
        "    ) -> tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Samples data from the static DGP.\n",
        "\n",
        "        Args:\n",
        "            n_obs (int): Number of observations to sample.\n",
        "            seed (int, optional): Random seed for reproducibility. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (x, y) arrays, each of length n_obs.\n",
        "        \"\"\"\n",
        "        rng = np.random.default_rng(seed)\n",
        "        x = rng.normal(size=n_obs)\n",
        "        u = rng.normal(size=n_obs)\n",
        "        y = self.beta0 + self.beta1 * x + u\n",
        "        return x, y"
      ],
      "id": "1eb3273d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Discussion of DGP Class\n",
        "\n",
        "We use a class to:\n",
        "\n",
        "- Capture a specific concern (data drawing)\n",
        "- Specify interfaces (a `sample()` method)\n",
        "- Encapsulate logic (class keeps its DGP details in `sample()`)\n",
        "\n",
        ". . .\n",
        "\n",
        "\n",
        "Example usage\n"
      ],
      "id": "a1e97f62"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "static_sampler = StaticNormalDGP(beta1=0.4)\n",
        "x, y = static_sampler.sample(n_obs=5, seed=1)\n",
        "print(f\"x: {x.round(2)} \\ny: {y.round(2)}\")"
      ],
      "id": "03827d3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Example: AR(1) Class\n",
        "\n",
        "A class for AR(1) with <span class=\"highlight\">same `sample()` interface</span>"
      ],
      "id": "832f1490"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| code-line-numbers: \"19-21\"\n",
        "class DynamicNormalDGP:\n",
        "    \"\"\"A data-generating process (DGP) for a dynamic linear model: y_t = beta0 + beta1*y_{t-1} + u_t.\n",
        "\n",
        "    Attributes:\n",
        "        beta0 (float): Intercept term.\n",
        "        beta1 (float): AR(1) coefficient.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, beta0: float = 0.0, beta1: float = 0.5):\n",
        "        \"\"\"Initializes the DGP with intercept and AR(1) coefficient.\n",
        "\n",
        "        Args:\n",
        "            beta0 (float): Intercept term. Defaults to 0.0.\n",
        "            beta1 (float): AR(1) coefficient. Defaults to 0.5.\n",
        "        \"\"\"\n",
        "        self.beta0: float = beta0\n",
        "        self.beta1: float = beta1\n",
        "\n",
        "    def sample(\n",
        "        self, n_obs: int, seed: int | None = None\n",
        "    ) -> tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Samples data from the dynamic DGP.\n",
        "\n",
        "        Args:\n",
        "            n_obs (int): Number of observations to sample.\n",
        "            seed (int, optional): Random seed for reproducibility. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (x, y) arrays, each of length n_obs.\n",
        "                  x is y_{t-1} (lagged y), and y is y_t.\n",
        "        \"\"\"\n",
        "        rng = np.random.default_rng(seed)\n",
        "        y = np.zeros(n_obs + 1)  # Extra observation for lag\n",
        "        u = rng.normal(size=n_obs + 1)\n",
        "        y[0] = self.beta0 + u[0]  # Initial condition\n",
        "        for t in range(1, n_obs + 1):\n",
        "            y[t] = self.beta0 + self.beta1 * y[t - 1] + u[t]\n",
        "        # Return lagged y as x and y[1:] as y\n",
        "        return y[:-1], y[1:]"
      ],
      "id": "09be6091",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Discussion: DGP Classes\n",
        "\n",
        "- Now `StaticNormalDGP` and `DynamicNormalDGP` capture our DGPs\n",
        "- Important: can interact with them in the <span class=\"highlight\">same way</span>:\n",
        "  - Ask their true `beta1` value\n",
        "  - `sample()` given number of poinst with given `seed`\n",
        "- In line with what simulation loop wants, all other logic kept inside\n",
        "\n",
        "#### Same Idea: Simple Estimator Class\n",
        "\n",
        "Hide estimator logic and only provide `fit()`\n"
      ],
      "id": "c96dbeb7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "class SimpleOLS:\n",
        "    \"\"\"A simple OLS estimator for the linear model y = beta0 + beta1*x + u.\n",
        "\n",
        "    Attributes:\n",
        "        beta0_hat (float): Estimated intercept. NaN until fit is called.\n",
        "        beta1_hat (float): Estimated slope. NaN until fit is called.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initializes the OLS estimator with no estimates.\"\"\"\n",
        "        self.beta0_hat: float = np.nan\n",
        "        self.beta1_hat: float = np.nan\n",
        "\n",
        "    def fit(self, x: np.ndarray, y: np.ndarray) -> None:\n",
        "        \"\"\"Fit OLS to the provided data.\n",
        "\n",
        "        Args:\n",
        "            x (np.ndarray): Independent variable (1D array).\n",
        "            y (np.ndarray): Dependent variable (1D array).\n",
        "        \"\"\"\n",
        " \n",
        "        # Add constant to x\n",
        "        X = np.column_stack([np.ones(len(x)), x])\n",
        "        # OLS estimation\n",
        "        beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
        "        self.beta0_hat, self.beta1_hat = beta_hat[0], beta_hat[1]"
      ],
      "id": "2132c896",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `SimpleOLS` In Action\n",
        "\n",
        "To fit an instance of `SimpleOLS`, just pass data:\n"
      ],
      "id": "d4fae6b8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "ols = SimpleOLS()\n",
        "x, y = static_sampler.sample(n_obs=5000, seed=1)\n",
        "ols.fit(x, y)\n",
        "print(f\"Estimated slope coefficient: {ols.beta1_hat:.3f}\")"
      ],
      "id": "a7d33063",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Now ready to put things together into simulation\n",
        "\n",
        "</div>\n",
        "\n",
        "### Simulation Runner Class {background=\"#43464B\"}\n",
        "\n",
        "#### Capturing Simulation Logic\n",
        "\n",
        "Now missing final piece — the simulation loop:\n",
        "\n",
        "- Will create appropriate `SimulationRunner` class\n",
        "- `SimulationRunner` composes DGP and estimator (part of its data)\n",
        "- With data, will run Monte Carlo simulation for given number of datasets\n",
        "\n",
        "\n",
        "\n",
        "#### Simulation Runner Implementation\n"
      ],
      "id": "7e2686c1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true \n",
        "class SimulationRunner:\n",
        "    \"\"\"Runs Monte Carlo simulations for a given DGP and estimator.\n",
        "\n",
        "    Attributes:\n",
        "        dgp: data-generating process with a sample() method.\n",
        "        estimator: estimator with a fit() method and beta1_hat attribute.\n",
        "        errors: array of estimation errors (beta1_hat - beta1) for each simulation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dgp: StaticNormalDGP | DynamicNormalDGP,\n",
        "        estimator: SimpleOLS,\n",
        "    ) -> None:\n",
        "        \"\"\"Initializes the simulation runner.\n",
        "\n",
        "        Args:\n",
        "            dgp: An instance of a DGP class (must implement `sample`).\n",
        "            estimator: An instance of an estimator class (must implement `fit`).\n",
        "        \"\"\"\n",
        "        self.dgp: StaticNormalDGP | DynamicNormalDGP = dgp\n",
        "        self.estimator: SimpleOLS = estimator\n",
        "        self.errors: np.ndarray = np.empty(0)\n",
        "\n",
        "    def simulate(self, n_sim: int, n_obs: int, first_seed: int | None = None) -> None:\n",
        "        \"\"\"Runs simulations and stores estimation errors.\n",
        "\n",
        "        Args:\n",
        "            n_sim (int): number of simulations to run.\n",
        "            n_obs (int): Number of observations per simulation.\n",
        "            first_seed (int | None): Starting random seed for reproducibility. \n",
        "                Defaults to None.\n",
        "        \"\"\"\n",
        "        # Preallocate array to hold estimation errors\n",
        "        self.errors = np.empty(n_sim)\n",
        "\n",
        "        # Run simulation\n",
        "        for sim_id in range(n_sim):\n",
        "            # Draw data\n",
        "            x, y = self.dgp.sample(n_obs, seed=first_seed + sim_id if first_seed else None)\n",
        "            # Fit model\n",
        "            self.estimator.fit(x, y)\n",
        "            # Store error\n",
        "            self.errors[sim_id] = self.estimator.beta1_hat - self.dgp.beta1"
      ],
      "id": "2b32f966",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Simulation Runner in Action\n",
        "\n",
        "Simulation flow now:\n",
        "\n",
        "- Create DGP and estimator\n",
        "- Pass to `SimulationRunner` and `simulate()`\n"
      ],
      "id": "275154c2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "# Initialize DGP and estimator\n",
        "static_dgp = StaticNormalDGP(beta0=0.0, beta1=0.5)\n",
        "ols_estimator = SimpleOLS()\n",
        "\n",
        "# Initialize and run simulation\n",
        "ols_static_sim = SimulationRunner(static_dgp, ols_estimator)\n",
        "ols_static_sim.simulate(n_sim=1000, n_obs=50, first_seed=1)\n",
        "\n",
        "# Summarize bias\n",
        "print(f\"Average estimation error (bias): {ols_static_sim.errors.mean():.4f}\")"
      ],
      "id": "8d879e32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.footer}\n",
        "\n",
        "The fact that we create and pass the DGP and estimator is an example of [dependency injection](https://en.wikipedia.org/wiki/Dependency_injection)\n",
        "\n",
        ":::\n",
        "\n",
        "#### Discussion I: What Just Happened?\n",
        " \n",
        "<div class=\"left-color\">\n",
        "\n",
        "DGP, estimator, and simulation runner are now only loosely connected\n",
        "\n",
        "</div>\n",
        "\n",
        ". . . \n",
        "\n",
        "<br>\n",
        "\n",
        "Benefits:\n",
        "\n",
        "- Can add new scenarios without touching the core simulation logic\n",
        "- Different people can work on these without conflicts\n",
        "- Can reuse components elsewhere\n",
        "- Easier to read and change the code\n",
        "\n",
        "#### Discussion II: Reproducibility in `simulate()`\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "`simulate()` ensures reproducibility with the `first_seed` argument\n",
        "\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "- `first_seed` — seed used for first dataset\n",
        "- $i$th dataset uses seed = `first_seed` + `i`\n",
        "- Ensures different datasets in different steps \n",
        "\n",
        "## Summarizing Results {background=\"#00100F\"}\n",
        " \n",
        " \n",
        "\n",
        "#### What To Do With Results\n",
        "\n",
        "`SimulationRunner` stores raw simulation results (here: full estimation errors in `errors` )\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "How these are handled — depends on what you want to do\n",
        "\n",
        "- Can add summary methods\n",
        "- Can create other objects that process run simulations (and generate figures)\n",
        " \n",
        ". . .\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "We will add a simple `summarize_bias()` method\n",
        "\n",
        "</div>\n",
        "\n",
        "#### Example: Adding A Summary to `SimulationRunner`\n"
      ],
      "id": "ea989899"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true \n",
        "#| code-line-numbers: \"45-51\"\n",
        "class SimulationRunner:\n",
        "    \"\"\"Runs Monte Carlo simulations for a given DGP and estimator.\n",
        "\n",
        "    Attributes:\n",
        "        dgp: Data-generating process with a `sample` method.\n",
        "        estimator: Estimator with a `fit` method and `beta1_hat` attribute.\n",
        "        errors: array of estimation errors (beta1_hat - beta1) for each simulation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dgp: \"StaticNormalDGP\" | \"DynamicNormalDGP\",\n",
        "        estimator: SimpleOLS,\n",
        "    ) -> None:\n",
        "        \"\"\"Initializes the simulation runner.\n",
        "\n",
        "        Args:\n",
        "            dgp: An instance of a DGP class (must implement `sample`).\n",
        "            estimator: An instance of an estimator class (must implement `fit`).\n",
        "        \"\"\"\n",
        "        self.dgp = dgp\n",
        "        self.estimator = estimator\n",
        "        self.errors = None\n",
        "\n",
        "    def simulate(self, n_sim: int, n_obs: int, first_seed: int | None = None) -> None:\n",
        "        \"\"\"Runs simulations and stores estimation errors.\n",
        "\n",
        "        Args:\n",
        "            n_sim (int): number of simulations to run.\n",
        "            n_obs (int): Number of observations per simulation.\n",
        "            first_seed (int | None): Random seed for reproducibility. Defaults to None.\n",
        "        \"\"\"\n",
        "        # Preallocate array to hold estimation errors\n",
        "        self.errors = np.empty(n_sim)\n",
        "\n",
        "        # Run simulation\n",
        "        for sim_id in range(n_sim):\n",
        "            # Draw data\n",
        "            x, y = self.dgp.sample(n_obs, seed=first_seed + sim_id if first_seed else None)\n",
        "            # Fit model\n",
        "            self.estimator.fit(x, y)\n",
        "            # Store error\n",
        "            self.errors[sim_id] = self.estimator.beta1_hat - self.dgp.beta1\n",
        "\n",
        "    def summarize_bias(self) -> None:\n",
        "        \"\"\"Prints the average estimation error (bias) for beta1. \n",
        "        \"\"\" \n",
        "        print(f\"Average estimation error (bias): {np.mean(self.errors):.4f}\")"
      ],
      "id": "58bae6d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Example: Summarizing AR(1) Simulation\n",
        "\n",
        "For example: compute bias in dynamic model with a lot of persistence: \n"
      ],
      "id": "86d17ae8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "# Initialize DGP and estimator\n",
        "dynamic_dgp = DynamicNormalDGP(beta0=0.0, beta1=0.95)\n",
        "ols_estimator = SimpleOLS()\n",
        "\n",
        "# Initialize and run simulation\n",
        "ols_dynamic_sim = SimulationRunner(dynamic_dgp, ols_estimator)\n",
        "ols_dynamic_sim.simulate(n_sim=1000, n_obs=50, first_seed=1)\n",
        "\n",
        "# Summarize bias\n",
        "ols_dynamic_sim.summarize_bias()"
      ],
      "id": "64a32711",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recap and Conclusions {background=\"#00100F\"}\n",
        " \n",
        "#### Recap\n",
        "\n",
        "<br>\n",
        "\n",
        "In this lecture we \n",
        "\n",
        "- Discussed the benefits of a more modular structure\n",
        "- Implemented such an approach using appropriate classes\n",
        "- Talked about basic result summaries\n",
        "\n",
        "#### How To Intepret Example Code\n",
        "\n",
        "\n",
        "Choose the appropriate level of complexity for your situation:\n",
        "\n",
        "- A brief simulation with one DGP does not need deep architecture and can be done with a monolithic function (last time)\n",
        "- A complex simulation involving many scenarios and estimators would benefit from a clearer structure\n",
        "\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "The specific implementations of today are not absolute, but an example of how to think\n",
        "\n",
        "</div>\n",
        "\n",
        "\n",
        "#### Further Improvements\n",
        "\n",
        "<br>\n",
        "\n",
        "Our simulation is in a good prototype shape, but can still improve some things:\n",
        "\n",
        "\n",
        "- Clean up relationships between DGP classes and organize them in a common family\n",
        "- Add simulation metadata (DGP name, estimator name for further purposes)\n",
        "- Tracking progress \n",
        "\n",
        "#### Next Questions\n",
        "\n",
        "<br>\n",
        "\n",
        "- How to clean up some loose ends in existing code?\n",
        "- How to organize running many simulations?\n",
        "- How to handle simulation results?\n",
        "- How to apply this logic to deeper statistical scenarios?\n",
        "\n",
        "#### References {.allowframebreaks visibility=\"uncounted\"}\n",
        "\n",
        "::: {#refs}\n",
        ":::"
      ],
      "id": "7faf49d0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}