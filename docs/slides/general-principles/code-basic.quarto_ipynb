{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Good Simulation Code I: Starting with Functions\"\n",
        "subtitle: \"Starting with a Monolithic Design for Small Simulations\"\n",
        "author: Vladislav Morozov  \n",
        "format:\n",
        "  revealjs:\n",
        "    include-in-header: \n",
        "      text: |\n",
        "        <meta name=\"description\" content=\"How to write good Monte Carlo simulation code in data science: basic monolithic function design for starting, with OLS bias example (lecture note slides)\"/> \n",
        "    width: 1150\n",
        "    slide-number: true\n",
        "    sc-sb-title: true\n",
        "    incremental: true   \n",
        "    logo: ../../themes/favicon.ico\n",
        "    footer: \"Code Design I: Using Functions\"\n",
        "    footer-logo-link: \"https://vladislav-morozov.github.io/simulations-course/\"\n",
        "    theme: ../../themes/slides_theme.scss\n",
        "    toc: TRUE\n",
        "    toc-depth: 2\n",
        "    toc-title: Contents\n",
        "    transition: convex\n",
        "    transition-speed: fast\n",
        "slide-level: 4\n",
        "title-slide-attributes:\n",
        "    data-background-color: \"#3c165cff\"\n",
        "    data-footer: \" \"\n",
        "filters:\n",
        "  - reveal-header \n",
        "embed-resources: true\n",
        "include-in-header: ../../themes/mathjax.html \n",
        "highlight-style: tango\n",
        "open-graph:\n",
        "    description: \"How to write good Monte Carlo simulation code in data science: basic monolithic function design for starting, with OLS bias example (lecture note slides)\" \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Introduction {background=\"#00100F\"}\n",
        " \n",
        "  \n",
        "\n",
        "### Lecture Info {background=\"#43464B\"}\n",
        "\n",
        "#### Learning Outcomes\n",
        "\n",
        "This lecture is about a starting approach to writing clean Monte Carlo code\n",
        "\n",
        "<br>\n",
        "\n",
        "By the end, you should be able to\n",
        "\n",
        "- Specify a basic simulation design\n",
        "- Start with a simple function-based simulation \n",
        "- Understand the importance of setting an RNG seed\n",
        "- Recognize the limitations of a monolithic design\n",
        "\n",
        "\n",
        "#### References\n",
        "\n",
        "::: {.nonincremental}\n",
        "\n",
        "Statistics:\n",
        "\n",
        "- Chapter 4 of @Hansen2022Econometrics for OLS\n",
        "- Chapter 14 of @Hansen2022Econometrics for time series basics\n",
        "\n",
        "Programming\n",
        "\n",
        "- Chapter 16-18 in @Lutz2025LearningPythonPowerful on functions in Python\n",
        "- Chapter 2-3 of @Hillard2020PracticesPythonPro on basics of design\n",
        "\n",
        ":::\n",
        "\n",
        " \n",
        "\n",
        "### Example Of This Block {background=\"#43464B\"}\n",
        "\n",
        "\n",
        "#### Context: Bias of OLS Estimator\n",
        "\n",
        "Consider the simple causal linear model:\n",
        "\n",
        "$$\n",
        "Y_{t}^x = \\beta_0 + \\beta_1 x + U_t, \\quad t=1, \\dots, T\n",
        "$$\n",
        "$Y_t^x$ — potential outcome under $x$ for observation $t$\n",
        "\n",
        "<br>\n",
        "\n",
        "Basic econometrics tells us that OLS estimator in regressing $Y_t$ on $(1, X_t)$ is\n",
        "\n",
        "- Unbiased if $\\E[U_t|X_1, \\dots, X_T] = 0$\n",
        "- Possibly biased otherwise \n",
        "\n",
        "#### Question of the Block: Does Bias Matter?\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Why should a user of OLS care about this bias?  \n",
        " \n",
        "</div>\n",
        "\n",
        "\n",
        " \n",
        "\n",
        " \n",
        "If bias is big, can lead to\n",
        "\n",
        "- Improperly centered confidence intervals\n",
        "- Wrong sign of point estimate\n",
        " \n",
        "\n",
        "$\\Rightarrow$ both can lead to incorrect policy conclusions if bias big\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "Statistical question of this block: <span class=\"highlight\">how big is the bias?</span>\n",
        "\n",
        "</div>\n",
        "\n",
        "\n",
        "#### Answer Approaches\n",
        "\n",
        "Remember: three ways to answer statistical questions:\n",
        "\n",
        "- Theory\n",
        "- Simulations\n",
        "- Empirical\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "This case: theory and empirical evaluation do not work\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Need to do simulations \n",
        "\n",
        "</div>\n",
        "\n",
        "#### Why Not Theory?\n",
        "\n",
        "Theory not fully satisfactory: expression for bias depends on the DGP for $(X_t, U_t)$:\n",
        "$$\n",
        "\\E[\\hat{\\bbeta}] - \\bbeta= \\E\\left[ (\\bW'\\bW)^{-1}\\bW'\\bU \\right]\n",
        "$$\n",
        "where $\\bW$ — $T\\times 2$ with $t$th row given by $(1, X_t)$\n",
        "\n",
        "\n",
        "- @Bao2007SecondOrderBiasMean: asymptotic order $O(1/T)$\n",
        "- Unclear if actual magnitude \"important in practice\"\n",
        "\n",
        "\n",
        "#### Why Not Use Real Data?\n",
        "\n",
        " \n",
        "Empirical data validation not an option both in causal and predictive settings:\n",
        "\n",
        "- Can never measure true bias even if believe in linear model\n",
        "- In predictive settings: don't even care about $\\hat{\\bbeta}$, only about predicted $\\hat{Y}_t$\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Have to recur to simulations\n",
        "\n",
        "</div>\n",
        "\n",
        "\n",
        " \n",
        "#### Questions of the Block: Simulations\n",
        "\n",
        "::: {.nonincremental}\n",
        " \n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "Technical question of the block: <span class=\"highlight\">how to think about and structure simulations in general?</span>\n",
        "  \n",
        " \n",
        "</div>\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "<br> \n",
        "\n",
        "This course block — talk mostly about <span class=\"highlight\">code design</span>\n",
        "\n",
        "- Our three-step simulation anatomy\n",
        "- Design sketches: monolithic (today) and more extensible (next lecture). Then organization and orchestration \n"
      ],
      "id": "0868b30e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from typing import Tuple"
      ],
      "id": "cc8ee8ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
        "plt.rcParams[\"font.sans-serif\"] = [\"Arial\"]\n",
        "\n",
        "BG_COLOR = \"whitesmoke\"\n",
        "THEME_COLOR = \"#3c165c\""
      ],
      "id": "b666f482",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specifying Our Simulation {background=\"#00100F\"}\n",
        " \n",
        "\n",
        " \n",
        "\n",
        "### Choosing Context {background=\"#43464B\"}\n",
        "\n",
        "#### Simulation Requirements\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "Recall that simulations should be \n",
        "\n",
        "- Realistic: need to think about relevant real world scenario to emulate\n",
        "\n",
        "- Targeted: \n",
        "    - Be specific in terms of target metrics\n",
        "    - Focus DGPs that cause differences in target metrics\n",
        " \n",
        "<div class=\"left-color\">\n",
        "\n",
        "Remember: simulations necessarily limited in scope — can only do finite number of experiments $\\Rightarrow$ need to focus\n",
        "\n",
        "</div>\n",
        "\n",
        "#### Choosing Scenario: Time Series\n",
        "\n",
        "As an example, we care about <span class=\"highlight\">time series</span>\n",
        "\n",
        "<br>\n",
        "\n",
        "What's relevant?\n",
        "\n",
        "- Possibility of dependence across time\n",
        "- Different strength of dependence\n",
        "- Different lengths of time series\n",
        "- (More advanced): data drift/time-varying DGP\n",
        "\n",
        ". . . \n",
        "\n",
        "We'll include the first three\n",
        "\n",
        "#### Metrics\n",
        "\n",
        "For simplicity, we will consider just one explicit metric:\n",
        "\n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "Our metric: absolute bias of OLS estimator of $\\beta_1$:\n",
        "\n",
        "$$\n",
        "\\text{Bias}(\\hat{\\beta}_1) = \\E[\\hat{\\beta}_1] - \\beta_1\n",
        "$$\n",
        "\n",
        "</div>\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "Other metrics:\n",
        "\n",
        "- Coverage of CIs based on the OLS estimator\n",
        "- Proportion of incorrect signs ($\\mathrm{sgn}(\\hat{\\beta}_1)\\neq \\mathrm{sgn}(\\beta_1)$)\n",
        "\n",
        "\n",
        "\n",
        "### Specifying DGPs {background=\"#43464B\"}\n",
        "\n",
        "#### The Problem of DGP Choice\n",
        "\n",
        "We now have to choose data generating processes that reflect\n",
        "\n",
        "- Dynamics of different strength\n",
        "- Different sample sizes\n",
        "\n",
        ". . .\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "\n",
        "Ideally: would specify based on some reference empirical datasets\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "\n",
        "Here: talk in a very stylized manner \n",
        "\n",
        "#### Static vs. Dynamic\n",
        "\n",
        "First dimension: include both static   and dynamic cases\n",
        "\n",
        "\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"46%\"}\n",
        "\n",
        " \n",
        "**Static**:\n",
        "\n",
        "$$  \\small\n",
        "Y_{t} = \\beta_0 + 0.5 X_{t} + U_{t}\n",
        "$$\n",
        "\n",
        "Covariate $X_t$ independent from $U_t$ and over time\n",
        "\n",
        ":::\n",
        "\n",
        "  \n",
        "::: {.column width=\"8%\"} \n",
        "\n",
        ":::\n",
        "\n",
        "::: {.column width=\"46%\"} \n",
        "  \n",
        "**Dynamic**:\n",
        "\n",
        "$$ \\small\n",
        "Y_{t} = \\beta_0 + \\beta_1 Y_{t-1} + U_{t}\n",
        "$$\n",
        "\n",
        "Dependence: $\\beta_1$ value\n",
        "\n",
        "$$  \\small\n",
        "\\beta_1 \\in \\curl{0, 0.5, 0.95}\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Bias appears in dynamic setting, but not static. Checking dynamic vs. static is <span class=\"highlight\">targeted</span>\n",
        "\n",
        "</div>\n",
        "\n",
        "\n",
        "#### Sample Size and Distributions of $U_t, X_t, Y_0$\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "\n",
        "::: {.nonincremental}\n",
        "\n",
        "Second and third design dimension:\n",
        "\n",
        "2. Sample sizes\n",
        "3. DGPs for variables not determined by model\n",
        "\n",
        ":::\n",
        "\n",
        "</div>\n",
        "\n",
        "\n",
        "To start with — keep things simple to focus on essentials:\n",
        "\n",
        "- One DGP per $U_t, X_t, Y_0$: each $N(0, 1)$\n",
        "- $T=50, 200$ \n",
        "\n",
        "\n",
        ". . .\n",
        "\n",
        "Different sample sizes: how bias changes (targeted)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Basic Functional Implementation {background=\"#00100F\"}\n",
        " \n",
        "\n",
        " \n",
        "\n",
        "### Implementation Approaches {background=\"#43464B\"}\n",
        "\n",
        "\n",
        "#### Summary So Far\n",
        "\n",
        "So far specified:\n",
        "\n",
        "- Metric\n",
        "- How each dataset should be generate\n",
        "- Size of each dataset\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Now time to actually implement — but how?\n",
        "\n",
        "</div>\n",
        "\n",
        "#### Two Approaches\n",
        "\n",
        "In this block talk about two approaches: \n",
        "\n",
        "- <span class=\"highlight\">Today</span>: monolithic, based on a single function (good for starting and small simulations)\n",
        "- <span class=\"highlight\">Next time</span>: a more modular approach (better for larger simulations and easier to develop)\n",
        "\n",
        "<br>\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Code examples of today: illustrative examples\n",
        "\n",
        "</div>\n",
        "\n",
        "\n",
        "#### General Advice\n",
        "\n",
        "How to not get overwhelmed — a good universal rule: \n",
        "\n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "Start with the simplest pieces and iterate from there\n",
        "\n",
        "\n",
        "</div>\n",
        " \n",
        "- Simulations are often fairly complex piece of code\n",
        "- Do not try to write the whole thing in one go\n",
        "- Do not be afraid of rewriting and improving things later\n",
        "\n",
        "\n",
        ". . . \n",
        "\n",
        "<br>\n",
        "\n",
        "Often: start with basic simulation function (today) and then refactor and split up (next time)\n",
        "\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "A good way to work is to follow a lightweight agile approach\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "### Basic Function {background=\"#43464B\"}\n",
        "\n",
        "\n",
        "\n",
        "#### Practice: Starting with the Static Case\n",
        " \n",
        "\n",
        "Our simplest thing: static model with a small sample\n",
        "$$\n",
        "Y_{t} = \\beta_0 + \\beta_1 X_t + U_t, \\quad T=50\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "Remember simulation anatomy: `for` many datasets we\n",
        "\n",
        "1. Draw 50 points $(X_t, Y_t)$\n",
        "2. Run OLS estimator $\\hat{\\beta}_1$\n",
        "3. Compute error $\\hat{\\beta}_1-\\beta_1$\n",
        "\n",
        "Simplest: wrap in a single function\n",
        "\n",
        "#### Example: Basic Simulation Function {.scrollable}\n"
      ],
      "id": "c3a680dc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "def simulate_ols(\n",
        "    n_sim: int = 1000, n_obs: int = 50, beta0: float = 0.0, beta1: float = 0.5\n",
        ") -> list[float]:\n",
        "    \"\"\"Simulates OLS estimation for a static/exogenous DGP: y = beta0 + beta1*x + u.\n",
        "\n",
        "    Args:\n",
        "        n_sim (int): Number of simulations to run. Defaults to 1000.\n",
        "        n_obs (int): Number of observations per simulation. Defaults to 100.\n",
        "        beta0 (float): True intercept value. Defaults to 0.\n",
        "        beta1 (float): True slope coefficient. Defaults to 0.5.\n",
        "\n",
        "    Returns:\n",
        "        list[float]: List of errors of beta1 estimates for each simulation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create container to store results\n",
        "    results_ols_errors = []\n",
        "\n",
        "    # Initialize the RNG\n",
        "    rng = np.random.default_rng()\n",
        "\n",
        "    # Core simulation loop\n",
        "    for _ in range(n_sim):\n",
        "        # 1. Draw data\n",
        "        x = rng.normal(size=n_obs)\n",
        "        u = rng.normal(size=n_obs)\n",
        "        y = beta0 + beta1 * x + u\n",
        "\n",
        "        # 2. Run OLS estimation\n",
        "        W = np.column_stack([np.ones(n_obs), x])\n",
        "        beta_hat = np.linalg.inv(W.T @ W) @ W.T @ y\n",
        "\n",
        "        # 3. Compute error\n",
        "        results_ols_errors.append(beta_hat[1] - beta1)\n",
        "\n",
        "    return results_ols_errors"
      ],
      "id": "ac4594b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Our First Results: Static Model\n",
        "\n",
        "Now can execute our simulation by calling function with default arguments:"
      ],
      "id": "f26e1f42"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "static_results = simulate_ols()\n",
        "print(f\"Bias (static DGP): {np.mean(static_results)}\")"
      ],
      "id": "914b3f18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Qualitatively:\n",
        "\n",
        "- Bias small relative to coefficients (recall $\\beta_1=0.5$)\n",
        "- Theory is confirmed\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "In practice you would usually wrap the function in a script and call from the command line\n",
        "\n",
        ":::\n",
        "\n",
        "#### Distribution of MC Estimates\n",
        "\n",
        "Can also take a look at density of estimates:\n"
      ],
      "id": "01d71acb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(14, 4.5))\n",
        "fig.patch.set_facecolor(BG_COLOR)\n",
        "fig.patch.set_edgecolor(THEME_COLOR)\n",
        "fig.patch.set_linewidth(5)\n",
        "sns.kdeplot(static_results, ax=ax, color=THEME_COLOR)\n",
        "plt.axvline(0, color=THEME_COLOR, linestyle=\"--\", label=\"No bias\")\n",
        "plt.axvline(np.mean(static_results), color=\"brown\", linestyle=\"--\", label=\"MC Estimate\")\n",
        "plt.title(\n",
        "    f\"Distribution of OLS Estimation Error under Static Model\",\n",
        "    loc=\"left\",\n",
        ")\n",
        "plt.xlabel(\"Estimation error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "82908e98",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Internal Reproducibility: Setting Seeds {background=\"#43464B\"}\n",
        "\n",
        "\n",
        "#### Problem: Lack of Reproducibility\n",
        "\n",
        "What happens if we rerun our code twice?\n"
      ],
      "id": "34434b2d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "static_results_1 = simulate_ols()\n",
        "static_results_2 = simulate_ols()\n",
        "print(f\"Bias (first run): {np.mean(static_results_1)}\")\n",
        "print(f\"Bias (second run): {np.mean(static_results_2)}\")"
      ],
      "id": "3038a3b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "- Same qualitative result\n",
        "- <span class=\"highlight\">Different</span> numerical results\n",
        "\n",
        ". . .\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Our results are not <span class=\"highlight\">reproducible</span> \n",
        "\n",
        "</div>\n",
        "\n",
        "#### Why No Reproducibility and How to Fix?\n",
        "\n",
        "Different data drawn by `rng` in different runs of the function\n",
        "\n",
        ". . . \n",
        "\n",
        "<br>\n",
        "\n",
        "To get same data, need to know that:\n",
        "\n",
        "- Computers cannot generate actual random numbers ([at least quickly and with guaranteed distribution](https://engineering.mit.edu/engage/ask-an-engineer/can-a-computer-generate-a-truly-random-number/))\n",
        "- Instead used <span class=\"highlight\">pseudo</span>random number generators — deterministic algorithms with \"good\" properties\n",
        "- PseudoRNG controlled by <span class=\"highlight\">seeds</span>\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Give same seed = get the same sequence of numbers\n",
        "\n",
        "</div>\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "For example, see [Wikipedia](https://en.wikipedia.org/wiki/Pseudorandom_number_generator) on pseudoRNG\n",
        "\n",
        ":::\n",
        "\n",
        "#### Setting the RNG Seed\n",
        "\n",
        "In practice: easy to provide a `seed` to our `rng`\n"
      ],
      "id": "6acc6755"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| code-line-numbers: \"1,6,15,25\"\n",
        "def simulate_ols(\n",
        "    n_sim: int = 1000,\n",
        "    n_obs: int = 50,\n",
        "    beta0: float = 0.0,\n",
        "    beta1: float = 0.5,\n",
        "    seed: int = 1,\n",
        ") -> list[float]:\n",
        "    \"\"\"Simulates OLS estimation for a static/exogenous DGP: y = beta0 + beta1*x + u.\n",
        "\n",
        "    Args:\n",
        "        n_sim (int): Number of simulations to run. Defaults to 1000.\n",
        "        n_obs (int): Number of observations per simulation. Defaults to 100.\n",
        "        beta0 (float): True intercept value. Defaults to 0.\n",
        "        beta1 (float): True slope coefficient. Defaults to 0.5.\n",
        "        seed (int): random number generator seed. Defaults to 1.\n",
        "\n",
        "    Returns:\n",
        "        list[float]: List of errors of beta1 estimates for each simulation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create container to store results\n",
        "    results_ols_errors = []\n",
        "\n",
        "    # Initialize the RNG\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    # Core simulation loop\n",
        "    for _ in range(n_sim):\n",
        "        # 1. Draw data\n",
        "        x = rng.normal(size=n_obs)\n",
        "        u = rng.normal(size=n_obs)\n",
        "        y = beta0 + beta1 * x + u\n",
        "\n",
        "        # 2. Run OLS estimation\n",
        "        W = np.column_stack([np.ones(n_obs), x])\n",
        "        beta_hat = np.linalg.inv(W.T @ W) @ W.T @ y\n",
        "\n",
        "        # 3. Compute error\n",
        "        results_ols_errors.append(beta_hat[1] - beta1)\n",
        "\n",
        "    return results_ols_errors"
      ],
      "id": "61ea9ffd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.footer}\n",
        "\n",
        "Setting a seed guarantees the same sequence of (pseudo)random numbers\n",
        "\n",
        ":::\n",
        " \n",
        "#### Rerunning Simulations\n",
        " \n",
        "Now rerunning with the same (default) seed gives the same results:\n"
      ],
      "id": "f1542416"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "static_results_1 = simulate_ols()\n",
        "static_results_2 = simulate_ols()\n",
        "print(f\"Bias (first run): {np.mean(static_results_1)}\")\n",
        "print(f\"Bias (second run): {np.mean(static_results_2)}\")"
      ],
      "id": "e25a5f82",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        " \n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "<span class=\"highlight\">Always set seeds explicitly to help reproducibility</span>\n",
        "\n",
        "</div>\n",
        "\n",
        "## Expanding the Simulation {background=\"#00100F\"}\n",
        " \n",
        "### Adding a Dynamic DGP {background=\"#43464B\"}\n",
        "\n",
        "\n",
        "#### Expanding the Simulation\n",
        " \n",
        "<div class='left-color'>\n",
        "\n",
        "Now need to expand simulations to add AR(1) design\n",
        "\n",
        "</div>\n",
        " \n",
        "Simplest way: just expand existing function\n",
        "\n",
        "- Add new DGP option `\"ar1\"`\n",
        "- Involves changing `simulate_ols` to have a new argument for `dgp_type`\n",
        "  - Old behavior: `dgp_type=\"static\"`\n",
        "  - New behavior: `dgp_type=\"ar1\"`\n",
        "- Also deal with losing one observation to $Y_{t-1}$\n",
        "\n",
        "#### Expanded Simulation Function: With AR(1) DGP\n"
      ],
      "id": "0c78c3e7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| code-line-numbers: \"7,16,35-43\"\n",
        "def simulate_ols(\n",
        "    n_sim: int = 1000,\n",
        "    n_obs: int = 50,\n",
        "    beta0: float = 0.0,\n",
        "    beta1: float = 0.5,\n",
        "    seed: int = 1,\n",
        "    dgp_type: str = \"static\",\n",
        ") -> list[float]:\n",
        "    \"\"\"Simulates OLS estimation for static or AR(1) DGP.\n",
        "    Args:\n",
        "        n_sim (int): Number of simulations to run. Defaults to 1000.\n",
        "        n_obs (int): Number of observations per simulation. Defaults to 100.\n",
        "        beta0 (float): True intercept value. Defaults to 0.\n",
        "        beta1 (float): True slope coefficient. Defaults to 0.5\n",
        "        seed (int): random number generator seed. Defaults to 1.\n",
        "        dgp_type (str): Type of DGP: \"static\" or \"ar1\". Defaults to \"static\".\n",
        "\n",
        "    Returns:\n",
        "        list[float]: List of errors of beta1 estimates for each simulation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create container to store results\n",
        "    results_ols_errors = []\n",
        "\n",
        "    # InitializeRNG\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    # Core simulation loop\n",
        "    for _ in range(n_sim):\n",
        "        # 1. Draw data\n",
        "        if dgp_type == \"static\":\n",
        "            x = rng.normal(size=n_obs)\n",
        "            u = rng.normal(size=n_obs)\n",
        "            y = beta0 + beta1 * x + u\n",
        "        elif dgp_type == \"ar1\":\n",
        "            y = np.zeros(n_obs + 1)\n",
        "            u = rng.normal(size=n_obs + 1)\n",
        "            y[0] = beta0 + u[0]\n",
        "            for t in range(1, n_obs + 1):\n",
        "                y[t] = beta0 + beta1 * y[t - 1] + u[t]\n",
        "            # Use the last n_obs elements of y as and the first n_obs as x\n",
        "            x = y[:-1]  # x is y lagged (n_obs elements)\n",
        "            y = y[1:]  # y[1:] is the dependent variable (n_obs elements)\n",
        "        else:\n",
        "            # Handle the case of giving the wrong DGP value\n",
        "            raise ValueError(\"Invalid DGP choice\")\n",
        "\n",
        "        # 2. Run OLS estimation\n",
        "        W = np.column_stack([np.ones(n_obs), x])\n",
        "        beta_hat = np.linalg.inv(W.T @ W) @ W.T @ y\n",
        "\n",
        "        # 3. Compute error\n",
        "        results_ols_errors.append(beta_hat[1] - beta1)\n",
        "\n",
        "    return results_ols_errors"
      ],
      "id": "3016d279",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Running AR(1) Simulation\n",
        " \n",
        "Can now run our simulations with $\\beta \\in \\curl{0, 0.5, 0.95}$:\n"
      ],
      "id": "b591bf82"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| code-line-numbers: \"1-3\"\n",
        "ar_results_no_pers = simulate_ols(beta1=0, dgp_type=\"ar1\")\n",
        "ar_results_med_pers = simulate_ols(beta1=0.5, dgp_type=\"ar1\")\n",
        "ar_results_high_pers = simulate_ols(beta1=0.95, dgp_type=\"ar1\")\n",
        "print(f\"Bias (no persistence): {np.mean(ar_results_no_pers):.3f}\")\n",
        "print(f\"Bias (medium persistence): {np.mean(ar_results_med_pers):.3f}\")\n",
        "print(f\"Bias (high persistence): {np.mean(ar_results_high_pers):.3f}\")"
      ],
      "id": "719640e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "Conclusions:\n",
        "\n",
        "<div class='left-color'>\n",
        "\n",
        "- More persistence = larger absolute bias\n",
        "- Direction: downward (underestimating)\n",
        "\n",
        "</div>\n",
        "  \n",
        "#### MC Distribution Under Persistence\n"
      ],
      "id": "e582135b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(14, 4.5))\n",
        "fig.patch.set_facecolor(BG_COLOR)\n",
        "fig.patch.set_edgecolor(THEME_COLOR)\n",
        "fig.patch.set_linewidth(5)\n",
        "sns.kdeplot(ar_results_high_pers, ax=ax, color=THEME_COLOR)\n",
        "plt.axvline(0, color=THEME_COLOR, linestyle=\"--\", label=\"No bias\")\n",
        "plt.axvline(np.mean(ar_results_high_pers), color=\"brown\", linestyle=\"--\", label=\"MC Estimate\")\n",
        "plt.title(\n",
        "    f\"Distribution of OLS Estimation Error under AR(1) with $\\\\beta_1=0.95$\",\n",
        "    loc=\"left\",\n",
        ")\n",
        "plt.xlabel(\"Estimation error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "196c2bab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Effect of Sample Size\n",
        " \n",
        "To check effect of sample size, use different values for `n_obs`:\n"
      ],
      "id": "fcb79890"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| code-line-numbers: \"1-3\"\n",
        "ar_results_no_pers = simulate_ols(beta1=0, n_obs=200, dgp_type=\"ar1\")\n",
        "ar_results_med_pers = simulate_ols(beta1=0.5, n_obs=200, dgp_type=\"ar1\")\n",
        "ar_results_high_pers = simulate_ols(beta1=0.95, n_obs=200, dgp_type=\"ar1\")\n",
        "print(f\"Bias (no persistence): {np.mean(ar_results_no_pers):.3f}\")\n",
        "print(f\"Bias (medium persistence): {np.mean(ar_results_med_pers):.3f}\")\n",
        "print(f\"Bias (high persistence): {np.mean(ar_results_high_pers):.3f}\")"
      ],
      "id": "aaa8f884",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "Conclusions:\n",
        "\n",
        "<div class='left-color'>\n",
        "\n",
        "Bias decays as sample size increases\n",
        "\n",
        "</div>\n",
        "  \n",
        "\n",
        "### Limitations of Functional Approach {background=\"#43464B\"}\n",
        "\n",
        "#### What's Good About The Functional Approach\n",
        "\n",
        "\n",
        "\n",
        "The monolithic function approach has a few pluses in our <span class=\"highlight\">small</span> simulation:\n",
        "\n",
        "- Was easy to create and design: just put all the components in one function in the same order\n",
        "- Everything is in one place: easy to look at the whole code\n",
        "\n",
        ". . . \n",
        "\n",
        "<br>\n",
        "\n",
        "<div class='left-color'>\n",
        "\n",
        "These advantages $\\Rightarrow$ why writing a simple function is usually a good starting place for new simulations\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "#### Problem: How To Expand Simulations?\n",
        "\n",
        "By now: a working base simulation\n",
        "\n",
        ". . . \n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "But what if we <span class=\"highlight\">expand our simulations</span>?\n",
        "\n",
        "- Try more DGPs (e.g. heavier tails for innovations, different $X$)\n",
        "- More sample sizes\n",
        "- Different models (not necessarily $Y_t = \\beta_0 + \\beta_1 X_t + U_t$)\n",
        "\n",
        "\n",
        "#### Limitations of Current Approach\n",
        "\n",
        "<div class='left-color'>\n",
        "\n",
        "We need a better approach to organizing simulations\n",
        "\n",
        "</div>\n",
        "\n",
        "- Basic approach is <span class=\"highlight\">fine</span> if you just want run one thing\n",
        "- But difficult if you want to expand more:\n",
        "    - Adding new DGPs would mean expanding simulation function even more\n",
        "    - We would have to remember to run all the different cases ourselves\n",
        " \n",
        ". . .\n",
        "\n",
        "Becomes difficult to scale and maintain\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "The simulation function becomes a [\"god object\"](https://en.wikipedia.org/wiki/God_object)\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Recap and Conclusions {background=\"#00100F\"}\n",
        " \n",
        "#### Recap\n",
        "\n",
        "<br>\n",
        "\n",
        "In this lecture we \n",
        " \n",
        "- Saw our first simulation\n",
        "- Talked about structuring simulation code in a single function + advantages and limitations of this approach\n",
        "- Discussed setting RNG seeds for reproducibility\n",
        "  \n",
        "\n",
        "#### Next Questions\n",
        "\n",
        "<br>\n",
        "\n",
        "- How to use a more modular and loosely modular design for larger simulations?\n",
        "- How to run many simulation scenarios at the same time?\n",
        "- How to apply these approaches to different statistical scenarios?\n",
        "\n",
        "#### References {.allowframebreaks visibility=\"uncounted\"}\n",
        "\n",
        "::: {#refs}\n",
        ":::"
      ],
      "id": "a1cca520"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}