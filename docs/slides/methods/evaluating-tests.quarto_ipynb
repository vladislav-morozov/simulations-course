{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Evaluating Hypothesis Tests\"\n",
        "subtitle: \"Simulating Test Power and Size for Comparing Tests\"\n",
        "author: Vladislav Morozov  \n",
        "format:\n",
        "  revealjs:\n",
        "    include-in-header: \n",
        "      text: |\n",
        "        <meta name=\"description\" content=\"Learn how to evaluate hypothesis tests in data science using Monte Carlo simulations; with worked power evaluation example (lecture note slides)\"/> \n",
        "    width: 1150\n",
        "    slide-number: true\n",
        "    sc-sb-title: true\n",
        "    incremental: true   \n",
        "    logo: ../../themes/favicon.ico\n",
        "    footer: \"Evaluating Hypothesis Tests\"\n",
        "    footer-logo-link: \"https://vladislav-morozov.github.io/simulations-course/\"\n",
        "    theme: ../../themes/slides_theme.scss\n",
        "    toc: TRUE\n",
        "    toc-depth: 2\n",
        "    toc-title: Contents\n",
        "    transition: convex\n",
        "    transition-speed: fast\n",
        "slide-level: 4\n",
        "title-slide-attributes:\n",
        "    data-background-color: \"#3c165cff\"\n",
        "    data-footer: \" \"\n",
        "filters:\n",
        "  - reveal-header \n",
        "embed-resources: true\n",
        "include-in-header: ../../themes/mathjax.html \n",
        "highlight-style: tango\n",
        "open-graph:\n",
        "    description: \"Learn how to evaluate hypothesis tests in data science using Monte Carlo simulations; with worked power evaluation example (lecture note slides)\" \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Introduction {background=\"#00100F\"}\n"
      ],
      "id": "b1000b65"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from scipy.stats import chi2\n",
        "BG_COLOR = \"whitesmoke\"\n",
        "THEME_COLOR = \"#3c165c\""
      ],
      "id": "d94e8adc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lecture Info {background=\"#43464B\"}\n",
        "\n",
        "#### Learning Outcomes\n",
        "\n",
        "This lecture is about evaluating hypothesis tests\n",
        "\n",
        "<br>\n",
        "\n",
        "By the end, you should be able to\n",
        "\n",
        " \n",
        "- Describe key properties of hypothesis tests \n",
        "- Add parallel execution and result handling to our simulation code \n",
        "- Use simulations to evaluate test power\n",
        " \n",
        "\n",
        "\n",
        "#### References on Hypothesis Testing\n",
        " \n",
        "<br>\n",
        "\n",
        "::: {.nonincremental}\n",
        "\n",
        " \n",
        "- [My slides from undergraduate econometrics](https://vladislav-morozov.github.io/econometrics-2/slides/vector/ols-inference.html) for some more theory and examples on linear hypothesis tests\n",
        "- Ch. 9 of @Hansen2022Econometrics\n",
        "- Ch. 9 in @Lehmann2022TestingStatisticalHypotheses on multiple comparison problems\n",
        "\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "#### References on Relevant Code Aspects\n",
        " \n",
        "<br>\n",
        "\n",
        "::: {.nonincremental}\n",
        "\n",
        "- Ch. 6 of @Lau2023LearningDataScience on pandas basics\n",
        "- Ch. 11 of @Lau2023LearningDataScience on plotting\n",
        "- Ch. 1-3 of @Antao2023FastPythonHigh regarding performance (but note that Python since [has added support for free threading](https://docs.python.org/3/howto/free-threading-python.html))\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "### Motivating Example Question {background=\"#43464B\"}\n",
        "\n",
        "#### Setting: Joint Hypotheses\n",
        " \n",
        "Often want to test <span class=\"highlight\">joint hypotheses</span>: hypotheses that involve several statements about parameters at the same time:\n",
        "\n",
        "<div class=\"left-color\">\n",
        "$$\n",
        "\\begin{aligned}\n",
        "& H_0: \\text{for all $k$ the statement $A_k$ is true} \\quad \\text{vs.} \\\\\n",
        "&  H_1: \\text{for at least some $k$, the statement $A_k$ is not true}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "Example: null that coefficients are zero ($A_k=\\curl{\\theta_k=0}$)\n",
        "$$\n",
        "\\begin{aligned}\n",
        "H_0: \\theta_k = 0, \\quad k=1, \\dots, p\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "#### Motivating Question for Simulation\n",
        "\n",
        "Two example approaches:\n",
        "\n",
        "- With a simultaneous (joint) test (e.g. Wald/$F$, LM, LR)\n",
        "- Testing each component separately (e.g. with a $t$-test) and combining the results (with adjusted $p$-values)\n",
        "\n",
        ". . . \n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "Question of today:\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "When do we generally use the first approach? \n",
        "\n",
        "</div>\n",
        " \n",
        "#### Goals for Today:\n",
        "\n",
        "How to answer this question? \n",
        "\n",
        "<br>\n",
        "\n",
        "Today talk about\n",
        "\n",
        "- What matters for comparing hypothesis tests\n",
        "- How to simulate tests\n",
        "- How to interpret results\n",
        "\n",
        "## Theory Essentials for Hypothesis Testings {background=\"#00100F\"}\n",
        " \n",
        "\n",
        "### Definitions {background=\"#43464B\"}\n",
        "\n",
        "\n",
        "\n",
        "#### Basic Setup: Hypotheses\n",
        "\n",
        "Suppose that we have a model with some parameters $\\theta$ (of whatever nature)\n",
        "\n",
        "<br>\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Two competing *hypotheses* (statements about parameters $\\theta$)\n",
        "$$\n",
        "H_0: \\theta\\in \\Theta_0 \\text{  vs.  } H_1: \\theta \\in \\Theta_1 \n",
        "$$\n",
        "for some non-intersecting $\\Theta_0$ and $\\Theta_1$\n",
        "\n",
        "</div>\n",
        "\n",
        "#### Examples of Hypotheses\n",
        "\n",
        "Example: linear model of the form:\n",
        "\n",
        "$$\\small\n",
        "Y_i  = \\sum_{k=0}^{p} \\beta_k X_i^{(k)}\n",
        "$$\n",
        "\n",
        "- Hypothesis on one parameter: $H_0: \\beta_k \\leq 0$ vs. $H_1: \\beta_k >0$\n",
        "- Hypothesis about many parameters: \n",
        "$$ \\small\n",
        "H_0: \\beta_0= \\dots = \\beta_p =0 \\quad \\text{ vs. } H_1: \\beta_k\\neq 0 \\text{ for some }k\n",
        "$$\n",
        "\n",
        "#### Definition of a Test\n",
        "\n",
        "A test is a <span class=\"highlight\">decision rule</span>: you see the sample and then you decide in favor of $H_0$ or $H_1$\n",
        "\n",
        "\n",
        ". . . \n",
        "\n",
        "<br>\n",
        "\n",
        "Formally:\n",
        "\n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "::: {#def-vector-inference-test}\n",
        "\n",
        "A test $T$ is a function of the sample $(X_1, \\dots, X_N)$ to the space $\\{ \\text{Reject } H_0$,  $\\text{Do not reject }H_0 \\}$\n",
        "\n",
        ":::\n",
        "\n",
        "</div>\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "Technically, @def-vector-inference-test is about <span class=\"highlight\">deterministic</span> tests, there are also randomized tests\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "#### Power\n",
        "\n",
        "<br>\n",
        "\n",
        "Key property of a hypothesis test: \n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "::: {#def-vector-inference-power}\n",
        "\n",
        "The power function $\\text{Power}_T(\\theta)$ of the test $T$ is the probability that $T$ rejects if $\\theta$ is the true parameter value:\n",
        "$$\n",
        "\\text{Power}_T(\\theta) = P(T(X_1, \\dots, X_N)=\\text{Reject }H_0|\\theta)\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        "</div>\n",
        "\n",
        " \n",
        "\n",
        "#### Test Size\n",
        "\n",
        "Maximal power under the null has a special name \n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "::: {#def-vector-inference-size}\n",
        "\n",
        "The <span class=\"highlight\"> size </span> $\\alpha$ of the test $T$ is \n",
        "$$\n",
        "\\alpha = \\max_{\\theta\\in\\Theta_0} \\text{Power}_T(\\theta)\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        "</div>\n",
        "\n",
        "In other words, the probability of falsely rejecting the null — <span class=\"highlight\">type I error</span>\n",
        "\n",
        "\n",
        "#### What Defines a Good Test? \n",
        "\n",
        "The best possible test has perfect detection:\n",
        "\n",
        "- Never rejects under $H_0$\n",
        "- Always reject under $H_1$\n",
        "\n",
        ". . . \n",
        "\n",
        "<br>\n",
        "\n",
        "Usually impossible in practice. Instead, we ask\n",
        "\n",
        "- Not too much false rejection under $H_0$ (e.g. $\\leq 5\\%$ of the time)\n",
        "- As much rejection as possible under $H_1$ \n",
        " \n",
        "\n",
        "#### Role of Size and Power\n",
        "\n",
        "\n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "Power function — key metric in comparing tests\n",
        "\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "::: {.nonincremental}\n",
        "\n",
        " \n",
        "\n",
        "You should prefer tests that\n",
        "\n",
        "- Control size correctly \n",
        "- Reject alternative more often (=use data more efficiently)\n",
        "\n",
        ":::\n",
        "\n",
        "### Tests and Test Statistics {background=\"#43464B\"}\n",
        "\n",
        " \n",
        " \n",
        " \n",
        "\n",
        "\n",
        "#### How Testing Works in General\n",
        "\n",
        "<div class=\"left-color\"> \n",
        "\n",
        "How do we construct a test/decision rule?\n",
        "\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        ". . .\n",
        "\n",
        "Basic approach:\n",
        "\n",
        "1. Pick a \"statistic\" (=some known function of the data) that behaves \"<span class=\"highlight\">differently</span>\" under $H_0$ and $H_1$\n",
        "2. Is the observed value of the statistic <span class=\"highlight\">compatible</span> with $H_0$? \n",
        "   - No $\\Rightarrow$ reject $H_0$ in favor or $H_1$\n",
        "   - Yes $\\Rightarrow$ do not reject $H_0$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### Measuring Compatibility with $H_0$\n",
        "\n",
        "<div class=\"left-color\">\n",
        "\n",
        "Recall: compare with <span class=\"highlight\">critical values</span> to measure compatibility with $H_0$\n",
        "\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "Critical values chosen to guarantee\n",
        "\n",
        "- Exact size (when possible)\n",
        "- Asymptotic size (otherwise) \n",
        "\n",
        "At least in the limit, the test should not falsely reject $H_0$ \"too much\"\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "The asymptotic size $\\alpha$ of the test $T$ is $\\alpha = \\lim_{N\\to\\infty} \\max_{\\theta\\in\\Theta_0}  P(T(X_1, \\dots, X_N)=\\text{Reject }H_0|\\theta)$\n",
        "\n",
        ":::\n",
        " \n",
        "\n",
        "#### Reminder: Main Classes of Statistics\n",
        "\n",
        "- In principle, can pick any statistic. Some are more \"standard\"\n",
        "- For testing hypotheses about coefficients, there are three main classes:\n",
        "  - Wald statistics: need only *unrestricted* estimates \n",
        "  - Lagrange multiplier (LM): need *restricted* estimates \n",
        "  - Likelihood ratio (LR): need both\n",
        " \n",
        "\n",
        "#### Example I: $t$-Test for $H_0: \\theta_k=0$ vs. $H_1: \\theta_k\\neq 0$\n",
        " \n",
        "\n",
        "Suppose that have estimator $\\hat{\\theta}_k$ such that\n",
        "$$ \\small\n",
        "\\sqrt{N}(\\hat{\\theta}_k-\\theta_k)\\xrightarrow{d} N(0, \\avar(\\hat{\\theta}_k))\n",
        "$$\n",
        "where $N$ is sample size\n",
        "\n",
        "\n",
        "Will base the test on the <span class=\"highlight\">$t$-statistic</span>:\n",
        "$$ \\small\n",
        "t = \\dfrac{\\hat{\\theta}_k}{\\sqrt{ \\widehat{\\avar}(\\hat{\\theta}_k)/N }  }\n",
        "$$\n",
        "\n",
        "\n",
        "#### Example I: Definition of $t$-Test  \n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "We call the following the <span class=\"highlight\">asymptotic size $\\alpha$ $t$-test</span>:\n",
        "\n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "Let $z_{1-\\alpha/2} = \\Phi^{-1}(1-\\alpha/2)$. Then\n",
        "\n",
        "- Reject $H_0$ is $\\abs{t}>z_{1-\\alpha/2}$\n",
        "- Do not reject $H_0$ is $\\abs{t}\\leq z_{1-\\alpha/2}$\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        " \n",
        "\n",
        "#### Example II: Wald Test for $H_0: \\bR\\btheta =\\bc$ vs. $H_1: \\bR\\btheta \\neq \\bc$\n",
        " \n",
        "Let $\\btheta= (\\theta_0, \\theta_1, \\dots, \\theta_p)$, $\\bR$ some matrix, $\\bc$ some vector\n",
        "\n",
        "Suppose that have estimator $\\hat{\\btheta}$ such that\n",
        "$$ \\small\n",
        "\\sqrt{N}(\\hat{\\btheta}-\\btheta)\\xrightarrow{d} N(0, \\avar(\\hat{\\btheta}))\n",
        "$$\n",
        "\n",
        "\n",
        "Will base the test on the <span class=\"highlight\">Wald statistic</span>:\n",
        "$$ \\small\n",
        "W = N\\left(  \\bR\\hat{\\bbeta}-\\bq   \\right)'\\left(\\bR\\widehat{\\avar}(\\bbeta)\\bR'\\right)^{-1}\\left(  \\bR\\hat{\\bbeta}-\\bq   \\right)\n",
        "$$ \n",
        "\n",
        "#### Example II: Definition of Wald Test\n",
        "\n",
        "We call the following the <span class=\"highlight\">asymptotic size $\\alpha$ Wald-test</span>:\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "Let $c_{1-\\alpha}$ solve $P(\\chi^2_k\\leq c_{1-\\alpha})=1-\\alpha$ where $k$ is the number of rows and rank of $\\bR$. Then\n",
        "\n",
        "- Reject $H_0$ if $W>c_{1-\\alpha}$\n",
        "- Do not reject $H_0$ if $W\\leq c_{1-\\alpha}$\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "#### Plot: PDF of $\\chi^2_k$ and Rejection Region (Shaded)\n"
      ],
      "id": "1dcd1b08"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Parameters for the chi-squared distribution\n",
        "df = 5\n",
        "\n",
        "# Generate the x values for the PDF\n",
        "x_vals = np.linspace(0, 20, 1000)\n",
        "\n",
        "# Compute the PDF values\n",
        "pdf_vals = chi2.pdf(x_vals, df)\n",
        "\n",
        "# Compute the 95th quantile\n",
        "quantile_95 = chi2.ppf(0.95, df)\n",
        "\n",
        "# Set up the figure and the axes\n",
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "fig.patch.set_facecolor(BG_COLOR)\n",
        "fig.patch.set_edgecolor(THEME_COLOR)\n",
        "fig.patch.set_linewidth(5)\n",
        "\n",
        "# Plot the PDF\n",
        "ax.plot(x_vals, pdf_vals, label=f'PDF of $\\\\chi^2_k$ distribution', color=THEME_COLOR)\n",
        "\n",
        "# Fill the area under the PDF to the right of the 95th quantile\n",
        "ax.fill_between(x_vals, pdf_vals, where=(x_vals >= quantile_95), color='darkorange', alpha=0.3)\n",
        "\n",
        "# Mark the 95th quantile\n",
        "ax.axvline(quantile_95, color='red', linestyle='--', label=\"$c_{1-\\\\alpha}$\")\n",
        "\n",
        "# Set the labels and title \n",
        "ax.set_ylabel('Density') \n",
        "ax.legend(loc='upper right')\n",
        "ax.set_ylim(0, 0.17)\n",
        "ax.set_xlim(0, 20)\n",
        "ax.set_xticklabels([])\n",
        "ax.set_yticklabels([])\n",
        "ax.set_facecolor(BG_COLOR)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "id": "223793c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing Simulation: Joint vs. Multiple Tests {background=\"#00100F\"}\n",
        "\n",
        "#### Plan For This Part\n",
        "\n",
        "Now turn to answering our motivating question: joint vs. mulitple tests for joint nulls\n",
        "\n",
        "<br>\n",
        "\n",
        "Plan:\n",
        "\n",
        "- A reminder on joint vs. multiple tests\n",
        "- Choosing simulation design: DGP, tests to compare \n",
        "\n",
        "After: implementation\n",
        "\n",
        "### Background: Joint and Multiple Tests {background=\"#43464B\"}\n",
        "\n",
        "#### Example Setting\n",
        "\n",
        "Suppose that have coefficients $\\theta_k$ and want to test the joint null\n",
        "$$\n",
        "H_0: \\theta_k = c_k, \\quad k=1, \\dots, p\n",
        "$$\n",
        "Have estimator $\\hat{\\btheta}$ such that $\\sqrt{N}(\\hat{\\btheta}-\\btheta)\\xrightarrow{d} N(0, \\avar(\\hat{\\btheta}))$\n",
        "\n",
        ". . . \n",
        "\n",
        "::: {.left-color}\n",
        "\n",
        "Two main approaches for testing $H_0$:\n",
        "\n",
        "- Single joint test\n",
        "- Multiple tests\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "#### Joint Tests\n",
        "\n",
        " \n",
        "::: {.left-color}\n",
        "\n",
        "\n",
        "A <span class=\"highlight\">joint test</span> uses a single statistic to conduct the text\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "<br>\n",
        "\n",
        "Example: Wald test based on\n",
        "\n",
        "$$\n",
        "W = N(\\hat{\\btheta}-\\bc)'(\\widehat{\\avar}(\\hat{\\btheta}))^{-1}(\\hat{\\btheta}-\\bc),\n",
        "$$\n",
        "Test based on comparing $W$ with $(1-\\alpha)$th quantile of $\\chi^2_p$\n",
        "\n",
        "#### Multiple Test\n",
        "\n",
        "::: {.left-color}\n",
        "\n",
        "\n",
        "A <span class=\"highlight\">multiple test</span> aggregates the decisions of many separate tests\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "For example, let \n",
        "$$ \\small \n",
        "t_k = \\dfrac{\\sqrt{N}(\\hat{\\btheta}_k-c_k)}{\\widehat{\\avar}(\\hat{\\btheta}_k)}\n",
        "$$\n",
        " \n",
        "A  <span class=\"highlight\">multiple $t$-test</span> for $H_0$ rejects if $\\max_{k=1, \\dots, p}\\lbrace \\abs{t_k}\\rbrace$ exceeds some prespecified critical value $c_{\\alpha}$\n",
        "\n",
        "\n",
        "#### Critical Values and Multiple Comparisons Problem\n",
        "\n",
        "\n",
        "::: {.left-color}\n",
        "\n",
        "\n",
        "Critical values of multiple tests have to be set to ensure overall correct size\n",
        "\n",
        ":::\n",
        "\n",
        "Have to be careful: e.g. with $p=2$ have\n",
        "$$\n",
        "\\begin{aligned}\n",
        "& P(\\text{test rejects}|H_0) \\\\\n",
        "& = P\\left( \\lbrace |{t}_1| \\geq c_{\\alpha}\\rbrace   |H_0 \\right) + P\\left(   \\lbrace |{t}_2| \\geq c_{\\alpha}\\rbrace |H_0 \\right)  \\\\\n",
        "& \\quad - P\\left( \\lbrace |{t}_1| \\geq c_{\\alpha}\\rbrace \\cap \\lbrace |{t}_2| \\geq c_{\\alpha}\\rbrace |H_0 \\right),\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Hence if each $t$-test is a size $\\alpha$-test, resulting multiple test has\n",
        "\n",
        "$$\n",
        "P(\\text{test rejects}|H_0) \\in [\\alpha, 2\\alpha]\n",
        "$$\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "See [this xckd](https://xkcd.com/882/) on multiple comparisons. Or see chapter 9 of @Lehmann2022TestingStatisticalHypotheses for theory\n",
        "\n",
        "::: \n",
        "\n",
        "### Choosing a Basic DGP {background=\"#43464B\"}\n",
        "\n",
        "#### Recap\n",
        " \n",
        "Now know the most important metrics:\n",
        "\n",
        " \n",
        "::: {.left-color}\n",
        "\n",
        "Should compare joint vs. multiple approach to testing in terms of <span class=\"highlight\">power</span>\n",
        "\n",
        "::: \n",
        "\n",
        "<br>\n",
        "\n",
        "But now key open questions:\n",
        "\n",
        "- Which tests exactly to use? \n",
        "- In which scenario? \n",
        "\n",
        " \n",
        "#### Technique: Reference Scenario\n",
        "\n",
        "Today: \n",
        "\n",
        "- Trying to understand joint vs. multiple choice \n",
        "- <span class=\"highlight\">Without any constraints on setting</span>\n",
        " \n",
        "::: {.rounded-box}\n",
        "\n",
        "When no constraint on setting is present, start with\n",
        "\n",
        "- Simplest DGPs\n",
        "- Simplest methods (here tests)\n",
        "\n",
        "::: \n",
        "Ideally: simplest = some kind of \"textbook\" reference setting\n",
        " \n",
        "#### Nice Reference Scenarios for Testing\n",
        "\n",
        "Very often in testing:\n",
        "\n",
        "- The nicest scenario is a simple linear model\n",
        "- Everything is normally distributed\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "Key reason: \n",
        "\n",
        "- Many practical tests are based on asymptotic normality\n",
        "- Hence exact normality = close to idealized asymptotic setting\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "There are theoretical reasons for importance of normality as a \"base\" case, see chapters 6-7 in @VanderVaart1998AsymptoticStatistics\n",
        "\n",
        ":::\n",
        "\n",
        "#### Reference Scenario: Simple Linear Model\n",
        "\n",
        "Simple linear model:\n",
        "$$\n",
        "Y_i = 1 + \\theta_1 X_i^{(1)} + \\theta_2 X_{i}^{(2)} + U_i\n",
        "$$\n",
        "\n",
        "\n",
        ". . . \n",
        "\n",
        "<br>\n",
        "\n",
        "Very simple kind of joint hypothesis:\n",
        "$$\n",
        "H_0: \\theta_1 = \\theta_2 = 0\n",
        "$$\n",
        "\n",
        "#### Reference DGPs: Distributions for $U_i$ and $(X_i^{(1)}, X_i^{(2)})$\n",
        " \n",
        "$$\n",
        "\\begin{aligned}\n",
        "U_{i} & \\sim N(0, 1), \\\\\n",
        "\\begin{pmatrix}\n",
        "X_i^{(1)} \\\\\n",
        "X_i^{(2)}\n",
        "\\end{pmatrix} & \\sim N\\left(\\begin{pmatrix}\n",
        "1 \\\\\n",
        "1\n",
        "\\end{pmatrix}, \\begin{pmatrix}\n",
        "1 & \\rho \\\\\n",
        "\\rho & 1\n",
        "\\end{pmatrix} \\right)\n",
        "\\end{aligned},\n",
        "$$\n",
        "where the correlation $\\rho$ runs between $-1$ and $1$\n",
        "\n",
        ". . . \n",
        "\n",
        "::: {.left-color}\n",
        "\n",
        "Varying $\\rho$ — key axis controlling geometry of many asymptotic joint tests — they depend on $\\avar(\\hat{\\bbeta})$\n",
        "\n",
        "::: \n",
        "\n",
        "#### DGPs: Coefficient Values\n",
        "\n",
        "Power function is function of $\\btheta=(\\theta_1, \\theta_2)$ \n",
        "\n",
        "$$ \\small\n",
        "\\text{Power}_T(\\btheta) = P(T(X_1, \\dots, X_N)=\\text{Reject }H_0|\\btheta)\n",
        "$$  \n",
        "\n",
        "::: {.left-color}\n",
        "\n",
        "Always need to look at DGPs that vary at least in coefficients in that enter in $H_0$ \n",
        "\n",
        "::: \n",
        "\n",
        "- Here: consider $\\theta_1=\\theta_2=c$ and vary $c$\n",
        "- Under each $c$ test $H_0:\\theta_1=\\theta_2=0$ \n",
        "\n",
        ". . . \n",
        "\n",
        "\n",
        "$\\Rightarrow$ DGPs vary in $c$ and $\\rho$\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "Not that restrictive to have $\\theta_1=\\theta_2$: can suitably rotate $(X_{i}^{(1)}, X_{i}^{(2)})$ to make any $(\\theta_1, \\theta_2)$ to  $\\theta_1=\\theta_2$.\n",
        "\n",
        "::: \n",
        "\n",
        "\n",
        "\n",
        "### Choosing Tests {background=\"#43464B\"}\n",
        "\n",
        "\n",
        "#### Which Tests to Use?\n",
        "\n",
        "In our case: think about which tests are the most popular\n",
        "\n",
        "<br>\n",
        "\n",
        "- For joint: Wald test is easiest theoretically and practically\n",
        "- For multiple: individual $t$ tests for $H_0: \\theta_1=0$ and $H_0: \\theta_2=0$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Will compare those based on OLS estimator, just need to choose <span class=\"highlight\">adjusted critical values for multiple $t$-test</span>\n",
        "\n",
        "\n",
        "#### Bonferroni Correction\n",
        "\n",
        "Recall: if each $t$-test is done at size $\\alpha$, then multiple $t$-test based on two has\n",
        "$$\n",
        "P(\\text{test rejects}|H_0) \\leq 2\\alpha\n",
        "$$\n",
        "\n",
        "::: {.left-color}\n",
        "\n",
        "If want overall multiple test to have size $\\leq \\alpha$, need to do each component test with size $\\alpha/2$ \n",
        ":::\n",
        "\n",
        "- Example: 2.5% individual tests for 5% overall\n",
        "- This is called the <span class=\"highlight\">Bonferroni correction</span>\n",
        "\n",
        "#### Role of $\\rho$\n",
        "\n",
        "$\\rho$ controls correlation between $\\hat{\\theta}_1$ and $\\hat{\\theta}_2$ with $\\mathrm{corr}(\\hat{\\theta}_1, \\hat{\\theta}_2) \\approx -\\rho$"
      ],
      "id": "901d76fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "from scipy.stats.distributions import chi2, norm\n",
        "\n",
        "# Define contour value c\n",
        "c = chi2.ppf(0.95, df=2)  # Change this to the desired value of c\n",
        "t_bound = norm.ppf(0.025 / 2)\n",
        "\n",
        "# Create a grid of x1 and x2 values\n",
        "x1 = np.linspace(-5, 5, 400)\n",
        "x2 = np.linspace(-5, 5, 400)\n",
        "X1, X2 = np.meshgrid(x1, x2)\n",
        "\n",
        "rhos = [-0.99, 0, 0.99]\n",
        "\n",
        "# Plot the contour for the specified value c\n",
        "fig, axs = plt.subplots(1, 3, figsize=(16, 4))\n",
        "fig.patch.set_facecolor(BG_COLOR)\n",
        "fig.patch.set_edgecolor(THEME_COLOR)\n",
        "fig.patch.set_linewidth(5)\n",
        "\n",
        "\n",
        "for ax, rho in zip(axs, rhos): \n",
        "    # Define the matrix A\n",
        "    A = np.array([[1, rho], [rho, 1]])  # Example symmetric positive-definite matrix\n",
        "    A = np.linalg.inv(A)\n",
        "\n",
        "    # Compute the quadratic form x'Ax\n",
        "    Z = A[0, 0] * X1**2 + A[1, 1] * X2**2 + 2 * A[0, 1] * X1 * X2\n",
        "\n",
        "\n",
        "    ax.contourf(X1, X2, Z, levels=[c, Z.max()], hatches=[\".\"], colors=[\"gold\"], alpha=0) \n",
        "    ax.set_xlabel(\"$\\\\hat{\\\\beta}_1$\", color=\"white\")\n",
        "    ax.set_ylabel(\"$\\\\hat{\\\\beta}_2$\", color=\"white\")\n",
        "\n",
        " \n",
        "    ax.set_xbound(-3, 3)\n",
        "    ax.set_ylim(-4.3, 4.3)\n",
        "\n",
        "    ax.add_patch(\n",
        "        Rectangle(\n",
        "            (t_bound, t_bound),\n",
        "            -2 * t_bound,\n",
        "            -2 * t_bound,\n",
        "            facecolor=\"none\",\n",
        "            ec=THEME_COLOR,\n",
        "            lw=2,\n",
        "            linestyle=\"--\",\n",
        "        )\n",
        "    ) \n",
        "\n",
        "    # Mask the region inside the rectangle\n",
        "    Z_masked = np.ma.masked_where(\n",
        "        (X1 >= t_bound) & (X1 <= -1 * t_bound) & (X2 >= t_bound) & (X2 <= -1 * t_bound), Z\n",
        "    )\n",
        " \n",
        "    ax.contour(X1, X2, Z, levels=[c], colors=\"gold\")\n",
        "\n",
        "    ax.text(-5, 4.7, \"Correlation($\\\\hat{\\\\theta}_1$, $\\\\hat{\\\\theta}_2$) = \" + str(rho),     fontsize=16,  color=\"black\")\n",
        "    ax.set_xlabel(\"$\\\\hat{\\\\theta}_1$\", color=\"black\")\n",
        "\n",
        "axs[0].set_ylabel(\"$\\\\hat{\\\\theta}_2$\", color=\"black\")\n",
        "axs[0].set_title(\n",
        "    \"Rejection regions: Wald (dotted) vs. adjusted multiple $t$-test (shaded)\\n\\n\",\n",
        "    color=\"black\",\n",
        "    loc=\"left\",\n",
        "    fontsize=16, \n",
        "    weight=\"bold\",\n",
        ");\n",
        "plt.show()"
      ],
      "id": "88b2c285",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementing Our Simulation {background=\"#00100F\"}\n",
        " \n",
        "\n",
        "### Simulation Runner and Tests {background=\"#43464B\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### Overall Code Structure\n",
        "\n",
        "Mostly use same code structure developed in first block\n",
        "\n",
        "<br>\n",
        "\n",
        "Some differences: \n",
        "\n",
        "- `tests` instead of `estimators`\n",
        "- Will add parallel execution\n",
        "- More results handling\n",
        "- Special approach to specifying DGPs\n",
        "\n",
        "#### File Structure\n",
        "\n",
        "```\n",
        "├── README.md\n",
        "├── requirements.txt\n",
        "├── dgps\n",
        "│   ├── __init__.py \n",
        "│   └── linear.py \n",
        "├── main.py\n",
        "├── results\n",
        "│   ├── ...\n",
        "├── sim_infrastructure\n",
        "│   ├── __init__.py \n",
        "│   ├── orchestrators.py\n",
        "│   ├── protocols.py \n",
        "│   ├── runner.py\n",
        "│   └── scenarios.py\n",
        "└── tests\n",
        "    ├── __init__.py \n",
        "    ├── joint.py\n",
        "    └── multiple.py\n",
        "```\n",
        "\"Infrastructure\" classes organized in separate folder so that `main.py` is the only   `.py` file in root\n",
        "\n",
        "\n",
        "#### Simulation Runner: Design\n",
        "\n",
        "What does execution look like for a single dataset?\n",
        "\n",
        "- Draw data\n",
        "- Apply test\n",
        "\n",
        ". . . \n",
        "\n",
        "<br>\n",
        "\n",
        "For many datasets:\n",
        "\n",
        "- Repeat above many times\n",
        "- Key: estimate power as frequency of rejections\n",
        "\n",
        "\n",
        "#### `SimulationRunner` Implementation\n",
        "\n",
        "\n",
        "\n",
        "```{.python filename=\"sim_infrastructure/runner.py\" code-line-numbers=\"73\"} \n",
        "\"\"\"\n",
        "Module for executing a given Monte Carlo scenario.\n",
        "\n",
        "This module contains the SimulationRunner class, which executes a scenario\n",
        "by combining a DGP and a test. It handles data generation, estimation, testing,\n",
        "and result collection.\n",
        "\n",
        "Classes:\n",
        "    SimulationRunner: Runs simulations and summarizes results.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from sim_infrastructure.protocols import DGPProtocol, TestProtocol\n",
        "\n",
        "\n",
        "class SimulationRunner:\n",
        "    \"\"\"Runs Monte Carlo simulations for a given DGP and estimator.\n",
        "\n",
        "    Attributes:\n",
        "        dgp: data-generating process with a sample() method and beta1 attribute.\n",
        "        estimator: estimator with a fit() method and beta1_hat attribute.\n",
        "        errors: array of estimation errors (beta1_hat - beta1) for each simulation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dgp: DGPProtocol,\n",
        "        test: TestProtocol,\n",
        "    ) -> None:\n",
        "        \"\"\"Initializes the simulation runner.\n",
        "\n",
        "        Args:\n",
        "            dgp: An instance of a DGP class (must implement `sample`).\n",
        "            estimator: An instance of an estimator class (must implement `fit`).\n",
        "        \"\"\"\n",
        "        self.dgp: DGPProtocol = dgp\n",
        "        self.test: TestProtocol = test\n",
        "        self.test_decisions: np.ndarray = np.empty(0)\n",
        "\n",
        "    def simulate(self, n_sim: int, n_obs: int, first_seed: int | None = None) -> None:\n",
        "        \"\"\"Runs simulations and stores estimation errors.\n",
        "\n",
        "        Args:\n",
        "            n_sim (int): number of simulations to run.\n",
        "            n_obs (int): Number of observations per simulation.\n",
        "            first_seed (int | None): Starting random seed for reproducibility.\n",
        "                Defaults to None.\n",
        "        \"\"\"\n",
        "        # Preallocate array to hold estimation errors\n",
        "        self.test_decisions = np.empty(n_sim)\n",
        "\n",
        "        # Run simulation\n",
        "        for sim_id in range(n_sim):\n",
        "            # Draw data\n",
        "            x, y = self.dgp.sample(\n",
        "                n_obs, seed=first_seed + sim_id if first_seed else None\n",
        "            )\n",
        "            # Test null of zero coefficients\n",
        "            self.test.test(x, y)\n",
        "            # Store error\n",
        "            self.test_decisions[sim_id] = self.test.decision\n",
        "\n",
        "    def summarize_results(self) -> dict:\n",
        "        \"\"\"Return a summary of results\n",
        "\n",
        "        Returns:\n",
        "            dict: power of current test at current DGP\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"test\": self.test.name,\n",
        "            \"covar_corr\": self.dgp.covar_corr,\n",
        "            \"common_coef_val\": self.dgp.common_coef_val,\n",
        "            \"power\": self.test_decisions.mean(),\n",
        "        }\n",
        "```\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "Notice how the `SimulationRunner` summarizes its result: that's the power function computation!\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "#### `tests/joint.py` Module: Wald Test\n",
        "\n",
        "```{.python filename=\"tests/joint.py\"}\n",
        "\"\"\"\n",
        "Module for joint tests for joint hypothesis.\n",
        "\n",
        "Classes:\n",
        "    WaldWithOLS: OLS-based Wald test that all non-intercept coefficients are zero.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.regression.linear_model import OLS\n",
        "\n",
        "\n",
        "class WaldWithOLS:\n",
        "    \"\"\"Class for applying Wald test to test null of zero coefficients.\n",
        "\n",
        "    Tailored to linear model\n",
        "        Y_i = theta0 + theta1 X_{i1} + ... + thetap X_{ip} + U_i\n",
        "    Tests the null:\n",
        "        H0: theta1 = ... = thetap = 0\n",
        "\n",
        "    Attributes:\n",
        "        name (str): test name, \"Wald\"\n",
        "        decision (np.bool): whether null is rejected\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.name: str = \"Wald\"\n",
        "        self.decision: np.bool\n",
        "\n",
        "    def test(self, x: pd.DataFrame, y: pd.DataFrame) -> None:\n",
        "        \"\"\"Carry out the Wald test with given data.\n",
        "\n",
        "        Args:\n",
        "            x (pd.DataFrame): covariates, including a leading constant column.\n",
        "            y (pd.DataFrame): outcomes.\n",
        "        \"\"\"\n",
        "        # Fit models\n",
        "        lin_reg = OLS(y, x)\n",
        "        lin_reg_fit = lin_reg.fit()\n",
        "\n",
        "        # Perform Wald test\n",
        "        num_covars = x.shape[1]\n",
        "        wald_restriction_matrix = np.concatenate(\n",
        "            (np.zeros((num_covars - 1, 1)), np.eye(num_covars - 1)), axis=1\n",
        "        )\n",
        "\n",
        "        wald_test = lin_reg_fit.wald_test(\n",
        "            wald_restriction_matrix,\n",
        "            use_f=False,\n",
        "            scalar=True,\n",
        "        )\n",
        "\n",
        "        self.decision = wald_test.pvalue <= 0.05\n",
        "```\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "`TestProtocol`: asks tests to have a `test()` method and a `decision` field\n",
        "\n",
        ":::\n",
        "\n",
        "#### `tests/multiple.py` Module: Multiple $t$-Test\n",
        "\n",
        "```{.python filename=\"tests/multiple.py\"}\n",
        "\"\"\"\n",
        "Module for multiple tests for joint hypothesis.\n",
        "\n",
        "Classes:\n",
        "    BonferronigMultipleTWithOLS: OLS-based multiple t-test that all non-intercept\n",
        "        coefficients are zero. Uses Bonferroni correction.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.regression.linear_model import OLS\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "\n",
        "class BonferronigMultipleTWithOLS:\n",
        "    \"\"\"Class for applying multiple t-test to test null of zero coefficients.\n",
        "\n",
        "    Tailored to linear model\n",
        "        Y_i = theta0 + theta1 X_{i1} + ... + thetap X_{ip} + U_i\n",
        "    Tests the null:\n",
        "        H0: theta1 = ... = thetap = 0\n",
        "\n",
        "    Attributes:\n",
        "        name (str): test name, \"Bonferroni t\"\n",
        "        decision (np.bool): whether null is rejected\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.name: str = \"Bonferroni t\"\n",
        "        self.decision: np.bool\n",
        "\n",
        "    def test(self, x: pd.DataFrame, y: pd.DataFrame) -> None:\n",
        "        \"\"\"Carry out the multiple t-test with given data.\n",
        "\n",
        "        Args:\n",
        "            x (pd.DataFrame): covariates, including a leading constant column.\n",
        "            y (pd.DataFrame): outcomes.\n",
        "        \"\"\"\n",
        "        # Fit models\n",
        "        lin_reg = OLS(y, x)\n",
        "        lin_reg_fit = lin_reg.fit()\n",
        "\n",
        "        # Perform multiple t-tests\n",
        "        p_vals_t = lin_reg_fit.pvalues.iloc[1:]\n",
        "        t_test_corrected_bonf = multipletests(\n",
        "            p_vals_t,\n",
        "            method=\"bonferroni\",  # Bonferroni\n",
        "        )\n",
        "        self.decision = t_test_corrected_bonf[0].sum() > 0\n",
        "\n",
        "```\n",
        "\n",
        "### Scenarios and Orchestrator {background=\"#43464B\"}\n",
        "\n",
        "#### Scenarios: Grid for $c$\n",
        "\n",
        "Again: power function depends on $c$ (from $\\theta_1=\\theta_2=c$)\n",
        "\n",
        "- In practice: can't compute function for infinite number of values of $c$\n",
        "- Instead compute for a <span class=\"highlight\">grid</span> of values of $c$\n",
        "\n",
        "<br>\n",
        "\n",
        ". . . \n",
        "\n",
        "Here: evaluate for 231 points evenly spaced between $-1.75$ and $+1.75$  — sufficient to capture everything\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "No special meaning for 231 — just a reasonable large number\n",
        "\n",
        ":::\n",
        "\n",
        "#### Scenarios: Grid for $\\rho$\n",
        "\n",
        "::: {.left-color}\n",
        "\n",
        "Want to also see the power function for <span class=\"highlight\">different values of covariate correlation $\\rho$</span>\n",
        "\n",
        ":::\n",
        "\n",
        "Will analyze for\n",
        "\n",
        "- 51 values of $\\rho$\n",
        "- Equally spaced between $-0.99$ and $+0.99$\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "That is, for every $\\rho$, compute power function on the $c$-grid\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "Using uneven number of grid points ensures that 0 is included in the grid\n",
        "\n",
        ":::\n",
        "\n",
        "#### Creating Grid of Scenarios\n",
        "\n",
        "- Different values of $c$ — different DGPs\n",
        "- $\\Rightarrow$ DGPs vary in both $c$ and $\\rho$\n",
        "\n",
        ". . . \n",
        "\n",
        "<br>\n",
        "\n",
        "Will create as follows:\n",
        "\n",
        "- Write a prototype DGP with $c$ and $\\rho$ as parameters\n",
        "- Use `scenarios.py` to create a DGP with every combination of $c$ and $\\rho$ from the grid\n",
        "- Overall: $51\\times 231 = 11781$ combinations \n",
        "\n",
        "#### Prototype DGP\n",
        "\n",
        "```{.python filename=\"dgps/linear.py\"} \n",
        "\"\"\"\n",
        "Module for linear data-generating processes (DGPs).\n",
        "\n",
        "This module contains classes for generating data from simple linear models.\n",
        "\n",
        "Classes:\n",
        "    BivariateLinearModel: A DGP for static linear models with normal variables,\n",
        "        adjustable correlation between covariates, and two variables + constant.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class BivariateLinearModel:\n",
        "    \"\"\"A data-generating process (DGP) for a static linear model\n",
        "\n",
        "    Attributes:\n",
        "        common_coef_val (float): Common values for theta1 and theta2\n",
        "        covar_corr (float): Correlation coefficient between covariates\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, common_coef_val: float, covar_corr: float) -> None:  \n",
        "        self.common_coef_val: float = common_coef_val\n",
        "        self.covar_corr: float = covar_corr\n",
        "\n",
        "    def sample(\n",
        "        self, n_obs: int, seed: int | None = None\n",
        "    ) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "        \"\"\"Samples data from the static DGP.\n",
        "\n",
        "        Args:\n",
        "            n_obs (int): Number of observations to sample.\n",
        "            seed (int, optional): Random seed for reproducibility. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (x, y) DataFrames, each of length n_obs.\n",
        "        \"\"\"\n",
        "        # Initialize RNG\n",
        "        rng = np.random.default_rng(seed)\n",
        "\n",
        "        # Construct mean and covariance for coefficients\n",
        "        x_mean = np.array([1, 0, 0])\n",
        "        x_covar = np.array([[0, 0, 0], [0, 1, self.covar_corr], [0, self.covar_corr, 1]])\n",
        "\n",
        "        # Construct vector of coefficients\n",
        "        thetas = np.array([1, self.common_coef_val, self.common_coef_val]\n",
        "                          )\n",
        "        # Draw covariates and residuals, combine into output \n",
        "        covariates = rng.multivariate_normal(\n",
        "            x_mean,\n",
        "            x_covar,\n",
        "            size=n_obs,\n",
        "        )\n",
        "        resids = rng.normal(0, np.sqrt(1), size=n_obs)\n",
        "        y = (covariates @ thetas) + resids\n",
        "\n",
        "        # Convert output into pandas dataframes with dynamic variable names for X\n",
        "        covariates_df = pd.DataFrame(\n",
        "            covariates,\n",
        "            columns=[f\"X{i}\" for i in range(covariates.shape[1])],\n",
        "        )\n",
        "        y_df = pd.DataFrame(\n",
        "            y,\n",
        "            columns=[\"y\"],\n",
        "        )\n",
        "        return covariates_df, y_df\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "#### `scenarios.py`\n",
        "\n",
        "```{.python filename=\"sim_infrastructure/scenarios.py\"}\n",
        "\"\"\"\n",
        "Module for defining simulation scenarios.\n",
        "\n",
        "This module contains scenarios for comparing power functions of tests under model:\n",
        "    Y = theta0  + theta1*x1 + theta2*x2 + u\n",
        "The null being tested is\n",
        "    H0: theta1=theta2=0\n",
        "\n",
        "Classes:\n",
        "    SimulationScenario: data class for scenarios\n",
        "\n",
        "Variables:\n",
        "    scenarios (list): list of scenarios to un.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "from dgps.linear import BivariateLinearModel\n",
        "from sim_infrastructure.protocols import DGPProtocol, TestProtocol\n",
        "from tests.joint import WaldWithOLS\n",
        "from tests.multiple import BonferronigMultipleTWithOLS\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class SimulationScenario:\n",
        "    \"\"\"A single simulation scenario: DGP, test, and sample size.\"\"\"\n",
        "\n",
        "    name: str  # For readability\n",
        "    dgp: type[DGPProtocol]\n",
        "    dgp_params: dict  # E.g. betas go here\n",
        "    test: type[TestProtocol]\n",
        "    test_params: dict  # E.g. reg_params go here\n",
        "    sample_size: int\n",
        "    n_simulations: int = 500\n",
        "    first_seed: int = 1\n",
        "\n",
        "\n",
        "# Create DGP combinations indexed by correlation and coefficient values\n",
        "common_coef_vals = np.linspace(-1.75, 1.75, 231)\n",
        "covar_corr_vals = np.linspace(-0.99, 0.99, 51)\n",
        "dgps = [\n",
        "    (\n",
        "        BivariateLinearModel,\n",
        "        {\"common_coef_val\": common_coef_val, \"covar_corr\": covar_corr},\n",
        "    )\n",
        "    for common_coef_val, covar_corr in product(common_coef_vals, covar_corr_vals)\n",
        "]\n",
        "\n",
        "# Create list of tests\n",
        "tests = [\n",
        "    (WaldWithOLS, {}),\n",
        "    (BonferronigMultipleTWithOLS, {}),\n",
        "]\n",
        "\n",
        "sample_sizes = [200]\n",
        "\n",
        "# Generate all combinations\n",
        "scenarios = [\n",
        "    SimulationScenario(\n",
        "        name=\"\", # will identify results through info from SimulationRunner\n",
        "        dgp=dgp_class,\n",
        "        dgp_params=dgp_params,\n",
        "        test=test_class,\n",
        "        test_params=test_params,\n",
        "        sample_size=size,\n",
        "    )\n",
        "    for (dgp_class, dgp_params), (\n",
        "        test_class,\n",
        "        test_params,\n",
        "    ), size in product(dgps, tests, sample_sizes)\n",
        "]\n",
        "```\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "#### Working With Many DGPs\n",
        "\n",
        "We end up many DGPs\n",
        "\n",
        "- But each scenario is \"separate\"\n",
        "- Scope for running simulations in <span class=\"highlight\">parallel</span>\n",
        " \n",
        "::: {.left-color} \n",
        "\n",
        "\n",
        "Will implement `SimulationOrchestrator` that can\n",
        "\n",
        "- Execute scenarios in parallel (with `ThreadPoolExecutor` under free-threaded Python 3.14+)\n",
        "- Collect the results\n",
        "- Track progress (with `tqdm`)\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.footer}\n",
        "\n",
        "Parallel computation is a deep topic. See @Antao2023FastPythonHigh on Python, but be aware of the removal of GIL in CPython starting from 3.14\n",
        "\n",
        ":::\n",
        "\n",
        "#### A Parallel `SimulationOrchestratorParallel`\n",
        "\n",
        "```{.python filename=\"sim_infrastructure/orchestrators.py\"}\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sim_infrastructure.runner import SimulationRunner\n",
        "from sim_infrastructure.scenarios import SimulationScenario\n",
        "\n",
        "\n",
        "class SimulationOrchestratorParallel:\n",
        "    \"\"\"Parallelized simulation orchestrator class.\"\"\"\n",
        "\n",
        "    def __init__(self, scenarios: list[SimulationScenario]) -> None:\n",
        "        self.scenarios = scenarios\n",
        "        self.summary_results = []\n",
        "\n",
        "    def run_single_scenario(self, scenario):\n",
        "        \"\"\"Run a single scenario and return the result dictionary.\"\"\"\n",
        "        dgp = scenario.dgp(**scenario.dgp_params)\n",
        "        estimator = scenario.test(**scenario.test_params)\n",
        "        runner = SimulationRunner(dgp, estimator)\n",
        "        runner.simulate(\n",
        "            n_sim=scenario.n_simulations,\n",
        "            n_obs=scenario.sample_size,\n",
        "            first_seed=scenario.first_seed,\n",
        "        )\n",
        "        return runner.summarize_results()\n",
        "\n",
        "    def run_all(self, max_workers=None):\n",
        "        \"\"\"Run all scenarios in parallel using ThreadPoolExecutor.\"\"\"\n",
        "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "            # Submit all scenarios to the executor\n",
        "            futures = {\n",
        "                executor.submit(self.run_single_scenario, scenario): scenario\n",
        "                for scenario in self.scenarios\n",
        "            }\n",
        "            # Collect results as they complete, with a progress bar\n",
        "            for future in tqdm(\n",
        "                as_completed(futures), total=len(futures), desc=\"Running simulations\"\n",
        "            ):\n",
        "                self.summary_results.append(future.result())\n",
        "```\n",
        "\n",
        "\n",
        "## Simulation Results {background=\"#00100F\"}\n",
        " \n",
        "\n",
        "#### Handling Simulation Results\n",
        " \n",
        "- Now have a large collection of results in the results field of the orchestrator: estimated power function for each combination of $c$, $\\rho$ and test\n",
        "- Can convert to pandas DataFrame and export as a CSV\n",
        "\n",
        ". . .\n",
        "\n",
        "Here: create a custom `ResultsProcessor` that processes results and export plots\n",
        "\n",
        "::: {.left-color}\n",
        "\n",
        "Sadly, <span class=\"highlight\">no general approaches</span> for making graphs — always a lot of customization and tight coupling to setting\n",
        "\n",
        "::: \n",
        "\n",
        "\n",
        "#### Resulting `main.py`\n",
        "\n",
        "```{.python filename=\"main.py\"}\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sim_infrastructure.orchestrators import SimulationOrchestratorParallel\n",
        "from sim_infrastructure.results_processor import ResultsProcessor\n",
        "from sim_infrastructure.scenarios import scenarios\n",
        "\n",
        "SIM_RESULTS_PATH = Path() / \"results\" / \"sim_results.csv\"\n",
        "PLOT_FOLDER = Path() / \"results\" / \"plots\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create and execute simulations\n",
        "    orchestrator = SimulationOrchestratorParallel(scenarios)\n",
        "    orchestrator.run_all()\n",
        "\n",
        "    # Export results\n",
        "    pd.DataFrame(orchestrator.summary_results).to_csv(SIM_RESULTS_PATH)\n",
        "\n",
        "    # Export plots\n",
        "    results_processor = ResultsProcessor(SIM_RESULTS_PATH, PLOT_FOLDER)\n",
        "    results_processor.export_all_plots()\n",
        "```\n",
        "  \n",
        " \n",
        " \n",
        "#### Power Surfaces\n",
        "\n",
        "![](../../../example-codes/2-joint-vs-multiple-tests/results/plots/power_surfaces.svg)\n",
        "\n",
        "\n",
        "#### Plotting Difference in Powers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"46%\"}\n",
        "\n",
        " \n",
        "![](../../../example-codes/2-joint-vs-multiple-tests/results/plots/power_diff.svg)\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "   \n",
        "::: {.column width=\"54%\"} \n",
        "\n",
        "::: {.nonincremental}\n",
        "\n",
        "- Hard to see differences directly from power surfaces\n",
        "- Can plot differences in power functions: power of Wald $-$ power of multiple $t$-test \n",
        "- Positive values: Wald more powerful\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "#### Interpreting Power Differences\n",
        "\n",
        "\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"46%\"}\n",
        "\n",
        " \n",
        "![](../../../example-codes/2-joint-vs-multiple-tests/results/plots/power_diff.svg)\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "   \n",
        "::: {.column width=\"54%\"} \n",
        "\n",
        "::: {.nonincremental}\n",
        "\n",
        "- Both control size correctly (see values at $c=0$)\n",
        "- Neither test dominates each other (both positive and negative values)\n",
        "- Wald has huge advantage with $\\mathrm{corr}(\\hat{\\theta}_1, \\hat{\\theta}_2) \\approx -1$\n",
        "- Multiple slightly better for $\\mathrm{corr}(\\hat{\\theta}_1, \\hat{\\theta}_2) \\approx 1$\n",
        "\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "#### Overall Statistical Conclusions\n",
        "\n",
        "Can we justify always using Wald tests based on this? \n",
        "\n",
        "<br>\n",
        "\n",
        "::: {.left-color}\n",
        "\n",
        "Yes. Wald test is <span class=\"highlight\">safe</span>\n",
        "\n",
        "- Never loses by much\n",
        "- Sometimes has huge power advantage\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Recap and Conclusions {background=\"#00100F\"}\n",
        " \n",
        "#### Recap\n",
        "\n",
        "<br>\n",
        "\n",
        "In this lecture we \n",
        "\n",
        "- Discussed key characteristics of hypothesis tests\n",
        "- Considered a worked example of comparing tests\n",
        "- Added parallel execution and result handling to our simulation code \n",
        "\n",
        "\n",
        "\n",
        "#### References {.allowframebreaks visibility=\"uncounted\"}\n",
        "\n",
        "::: {#refs}\n",
        ":::"
      ],
      "id": "bc66aac0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}